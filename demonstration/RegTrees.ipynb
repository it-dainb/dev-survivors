{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ddd2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalene extension successfully loaded. Note: Scalene currently only\n",
      "supports CPU+GPU profiling inside Jupyter notebooks. For full Scalene\n",
      "profiling, use the command line version.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pathlib, tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from joblib import Parallel, delayed\n",
    "from scipy import stats\n",
    "\n",
    "from survivors import metrics as metr\n",
    "from survivors import constants as cnt\n",
    "from survivors import criteria as crit\n",
    "from numba import njit, jit, int32, float64\n",
    "from lifelines import KaplanMeierFitter, NelsonAalenFitter\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "from survivors.ensemble import BootstrapCRAID\n",
    "import survivors.datasets as ds\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "%load_ext line_profiler\n",
    "%load_ext scalene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ae7e3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "from scipy import stats\n",
    "from survivors.tree.stratified_model import KaplanMeier, FullProbKM, NelsonAalen, KaplanMeierZeroAfter\n",
    "from survivors.metrics import ibs_WW, auprc\n",
    "from survivors.constants import get_y\n",
    "\n",
    "\"\"\" Auxiliary functions \"\"\"\n",
    "\n",
    "\n",
    "@njit('f4(f4[:], f4[:], f4[:], f4[:], u4, f4[:])', cache=True)\n",
    "def lr_hist_statistic(time_hist_1, time_hist_2, cens_hist_1, cens_hist_2,\n",
    "                      weightings, obs_weights):\n",
    "    N_1_j = np.cumsum(time_hist_1[::-1])[::-1]\n",
    "    N_2_j = np.cumsum(time_hist_2[::-1])[::-1]\n",
    "    ind = np.where((cens_hist_1 + cens_hist_2 != 0) & (N_1_j * N_2_j != 0))[0]\n",
    "#     ind = np.where((cens_hist_1 + cens_hist_2 != 0) & (N_1_j + N_2_j > 0))[0]\n",
    "    if ind.shape[0] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    N_1_j = N_1_j[ind]\n",
    "    N_2_j = N_2_j[ind]\n",
    "    O_1_j = cens_hist_1[ind]\n",
    "    O_2_j = cens_hist_2[ind]\n",
    "\n",
    "    N_j = N_1_j + N_2_j\n",
    "    O_j = O_1_j + O_2_j\n",
    "    E_1_j = N_1_j * O_j / N_j\n",
    "    \n",
    "    res = np.zeros((N_j.shape[0], 3), dtype=np.float32)\n",
    "    res[:, 1] = O_1_j - E_1_j\n",
    "    res[:, 2] = E_1_j * (N_j - O_j) * N_2_j / (N_j * (N_j))  # N_j\n",
    "    \n",
    "    res[:, 0] = 1.0\n",
    "    if weightings == 2:\n",
    "        res[:, 0] = N_j\n",
    "    elif weightings == 3:\n",
    "        res[:, 0] = np.sqrt(N_j)\n",
    "    elif weightings == 4:\n",
    "        res[:, 0] = np.cumprod((1.0 - O_j / (N_j + 1)))\n",
    "    elif weightings == 5:\n",
    "        res[:, 0] = obs_weights[ind]\n",
    "    elif weightings == 6:\n",
    "        res[:, 0] = O_j/N_j\n",
    "    elif weightings == 7:\n",
    "        res[:, 0] = np.cumprod((1.0 - O_j / (N_j + 1)))\n",
    "    elif weightings == 8:\n",
    "        res[:, 0] = N_j/(N_1_j*N_2_j)\n",
    "#     var = np.trapz((res[:, 0] * res[:, 0] * res[:, 2]), bins[ind])\n",
    "#     num = np.trapz((res[:, 0] * res[:, 1]), bins[ind])\n",
    "    var = (res[:, 0] * res[:, 0] * res[:, 2]).sum()\n",
    "    num = (res[:, 0] * res[:, 1]).sum()\n",
    "    \n",
    "    if var == 0:\n",
    "        return 0\n",
    "    stat_val = np.power(num, 2) / var\n",
    "\n",
    "    if weightings == 7:\n",
    "        res[:, 0] = 1 - res[:, 0]\n",
    "        stat_val2 = np.power((res[:, 0] * res[:, 1]).sum(), 2) / ((res[:, 0] * res[:, 0] * res[:, 2]).sum())\n",
    "        stat_val = max(stat_val, stat_val2)\n",
    "    return stat_val\n",
    "\n",
    "def weight_hist_stat(time_hist_1, time_hist_2, cens_hist_1=None, cens_hist_2=None, \n",
    "                     weights_hist=None, weightings=\"\"):\n",
    "    try:\n",
    "        if cens_hist_1 is None:\n",
    "            cens_hist_1 = time_hist_1\n",
    "        if cens_hist_2 is None:\n",
    "            cens_hist_2 = time_hist_2\n",
    "        if weights_hist is None:\n",
    "            weights_hist = np.ones_like(time_hist_1)\n",
    "        d = {\"logrank\": 1, \"wilcoxon\": 2, \"tarone-ware\": 3, \"peto\": 4, \"weights\": 5}\n",
    "        d.update({\"diff\": 6, \"maxcombo\": 7, \"frac\": 8})\n",
    "        weightings = d.get(weightings, 1)\n",
    "        logrank = lr_hist_statistic(time_hist_1.astype(\"float32\"),\n",
    "                                    time_hist_2.astype(\"float32\"),\n",
    "                                    cens_hist_1.astype(\"float32\"),\n",
    "                                    cens_hist_2.astype(\"float32\"),\n",
    "                                    np.uint32(weightings),\n",
    "                                    weights_hist.astype(\"float32\")\n",
    "                                   )\n",
    "        return logrank\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        return 0.0\n",
    "\n",
    "    \n",
    "def optimal_criter_split_hist(left_time_hist, left_cens_hist,\n",
    "                              right_time_hist, right_cens_hist,\n",
    "                              na_time_hist, na_cens_hist, weights_hist, criterion, dis_coef, \n",
    "                              apr_t_distr, apr_e_distr, l_reg):\n",
    "    none_to = 0\n",
    "    max_stat_val = 1.0\n",
    "    \n",
    "#     n1 = np.cumsum(left_time_hist[::-1])[::-1] + 1\n",
    "#     n2 = np.cumsum(right_time_hist[::-1])[::-1] + 1\n",
    "#     cf = n1/(n1 + n2)\n",
    "    \n",
    "    n1 = np.sum(left_time_hist)\n",
    "    n2 = np.sum(right_time_hist)\n",
    "    cf = n1/(n1 + n2)\n",
    "    \n",
    "#     ev = np.sum(left_cens_hist + right_cens_hist)\n",
    "#     ev_cf = ev/(n1 + n2)\n",
    "    \n",
    "    if na_time_hist.shape[0] > 0:\n",
    "        a = weight_hist_stat(left_time_hist + na_time_hist + l_reg*apr_t_distr*cf, \n",
    "                             right_time_hist + l_reg*apr_t_distr*(1 - cf),\n",
    "                             left_cens_hist + na_cens_hist + l_reg*apr_e_distr*cf, \n",
    "                             right_cens_hist + l_reg*apr_e_distr*(1 - cf),\n",
    "                             weights_hist, weightings=criterion)\n",
    "        b = weight_hist_stat(left_time_hist + l_reg*apr_t_distr*cf, \n",
    "                             right_time_hist + na_time_hist + l_reg*apr_t_distr*(1 - cf),\n",
    "                             left_cens_hist + l_reg*apr_e_distr*cf, \n",
    "                             right_cens_hist + na_cens_hist + l_reg*apr_e_distr*(1 - cf),\n",
    "                             weights_hist, weightings=criterion)\n",
    "        # Nans move to a leaf with maximal statistical value\n",
    "        none_to = int(a < b)\n",
    "        max_stat_val = max(a, b)\n",
    "    else:\n",
    "        max_stat_val = weight_hist_stat(left_time_hist + l_reg*apr_t_distr*cf,\n",
    "                                        right_time_hist + l_reg*apr_t_distr*(1 - cf),\n",
    "                                        left_cens_hist + l_reg*apr_e_distr*cf, \n",
    "                                        right_cens_hist + l_reg*apr_e_distr*(1 - cf),\n",
    "                                        weights_hist, weightings=criterion)\n",
    "    return (max_stat_val, none_to)\n",
    "\n",
    "\n",
    "def get_attrs(max_stat_val, values, none_to, l_sh, r_sh, nan_sh):\n",
    "    attrs = dict()\n",
    "    attrs[\"stat_val\"] = max_stat_val\n",
    "    attrs[\"values\"] = values\n",
    "    if none_to:\n",
    "        attrs[\"pos_nan\"] = [0, 1]\n",
    "        attrs[\"min_split\"] = min(l_sh, r_sh + nan_sh)\n",
    "    else:\n",
    "        attrs[\"pos_nan\"] = [1, 0]\n",
    "        attrs[\"min_split\"] = min(l_sh + nan_sh, r_sh)\n",
    "    return attrs\n",
    "\n",
    "\n",
    "def transform_woe_np(x_feat, y):\n",
    "    N_T = y.shape[0]\n",
    "    N_D = y.sum()\n",
    "    N_D_ = N_T - N_D\n",
    "    x_uniq = np.unique(x_feat)\n",
    "    x_dig = np.digitize(x_feat, x_uniq) - 1\n",
    "\n",
    "    df_woe_iv = np.vstack([np.bincount(x_dig[y == 0], minlength=x_uniq.shape[0]),\n",
    "                           np.bincount(x_dig[y == 1], minlength=x_uniq.shape[0])])\n",
    "    all_0 = df_woe_iv[0].sum()\n",
    "    all_1 = df_woe_iv[1].sum()\n",
    "\n",
    "    p_bd = (df_woe_iv[1] + 1e-5) / (N_D + 1e-5)\n",
    "    p_bd_ = (df_woe_iv[0] + 1e-5) / (N_D_ + 1e-5)\n",
    "    p_b_d = (all_1 - df_woe_iv[1] + 1e-5) / (N_D + 1e-5)\n",
    "    p_b_d_ = (all_0 - df_woe_iv[0] + 1e-5) / (N_D_ + 1e-5)\n",
    "\n",
    "    woe_pl = np.log(p_bd / p_bd_)\n",
    "    woe_mn = np.log(p_b_d / p_b_d_)\n",
    "    descr_np = np.vstack([x_uniq, woe_pl - woe_mn])\n",
    "    features_woe = dict(zip(descr_np[0], descr_np[1]))\n",
    "    woe_x_feat = np.vectorize(features_woe.get)(x_feat)\n",
    "    return (woe_x_feat, descr_np)\n",
    "\n",
    "\n",
    "def get_sa_hists(time, cens, minlength=1, weights=None):\n",
    "    if time.shape[0] > 0:\n",
    "        time_hist = np.bincount(time, minlength=minlength)\n",
    "        cens_hist = np.bincount(time, weights=cens, minlength=minlength)\n",
    "    else:\n",
    "        time_hist, cens_hist = np.array([]), np.array([])\n",
    "    return time_hist, cens_hist\n",
    "\n",
    "\n",
    "def select_best_split_info(attr_dicts, type_attr, bonf=True, descr_woe=None):\n",
    "    best_attr = max(attr_dicts, key=lambda x: x[\"stat_val\"])\n",
    "    \n",
    "    best_attr[\"p_value\"] = stats.chi2.sf(best_attr[\"stat_val\"], df=1)\n",
    "    best_attr[\"sign_split\"] = len(attr_dicts)\n",
    "    if best_attr[\"sign_split\"] > 0:\n",
    "        best_attr[\"src_val\"] = best_attr['values']\n",
    "        if type_attr == \"cont\":\n",
    "            best_attr[\"values\"] = [f\" <= {best_attr['values']}\", f\" > {best_attr['values']}\"]\n",
    "        elif type_attr == \"woe\" or type_attr == \"categ\":\n",
    "            ind = descr_woe[1] <= best_attr[\"values\"]\n",
    "            l, r = list(descr_woe[0, ind]), list(descr_woe[0, ~ind])\n",
    "            best_attr[\"values\"] = [f\" in {e}\" for e in [l, r]]\n",
    "        if bonf:\n",
    "            best_attr[\"p_value\"] *= best_attr[\"sign_split\"]\n",
    "    return best_attr\n",
    "\n",
    "\n",
    "def split_time_to_bins(time, apr_times):\n",
    "    if apr_times is None:\n",
    "        return np.searchsorted(np.unique(time), time)\n",
    "#         return np.searchsorted(np.quantile(time, np.arange(6)/5), time)\n",
    "    return np.searchsorted(np.unique(apr_times), time)\n",
    "#     return np.searchsorted(np.quantile(apr_times, np.arange(6)/5), time)\n",
    "\n",
    "\n",
    "def hist_best_attr_split(arr, criterion=\"logrank\", type_attr=\"cont\", weights=None, thres_cont_bin_max=100,\n",
    "                         signif=1.0, signif_stat=0.0, min_samples_leaf=10, bonf=True, verbose=0, balance=False, \n",
    "                         apr_time=None, apr_event=None, l_reg=0, **kwargs):\n",
    "    best_attr = {\"stat_val\": signif_stat, \"p_value\": signif,\n",
    "                 \"sign_split\": 0, \"values\": [], \"pos_nan\": [1, 0]}\n",
    "    if arr.shape[1] < 2 * min_samples_leaf:\n",
    "        return best_attr\n",
    "    vals = arr[0].astype(\"float\")\n",
    "    cens = arr[1].astype(\"uint\")\n",
    "    dur = arr[2].astype(\"float\")\n",
    "    \n",
    "    if np.sum(cens) == 0:\n",
    "        return best_attr\n",
    "    if weights is None:\n",
    "        weights = np.ones_like(dur)\n",
    "        \n",
    "    weights_hist = None\n",
    "    dur = split_time_to_bins(dur, apr_time)\n",
    "    \n",
    "    if apr_time is None:\n",
    "        time_bins = np.unique(dur)\n",
    "        max_bin = dur.max()\n",
    "        apr_t_distr = np.zeros(max_bin + 1)\n",
    "        apr_e_distr = np.zeros(max_bin + 1)\n",
    "    else:\n",
    "        time_bins = np.unique(apr_time)\n",
    "        apr_time_1 = split_time_to_bins(apr_time, apr_time)\n",
    "        max_bin = apr_time_1.max()\n",
    "        apr_t_distr, apr_e_distr = get_sa_hists(apr_time_1, apr_event, minlength=max_bin + 1)\n",
    "    \n",
    "    ind = np.isnan(vals)\n",
    "\n",
    "    # split nan and not-nan\n",
    "    dur_notna = dur[~ind]\n",
    "    cens_notna = cens[~ind]\n",
    "    vals_notna = vals[~ind]\n",
    "    weights_notna = weights[~ind]\n",
    "\n",
    "    dis_coef = 1\n",
    "    if balance:\n",
    "        dis_coef = (cens.shape[0] - np.sum(cens)) / np.sum(cens)\n",
    "\n",
    "    if dur_notna.shape[0] < min_samples_leaf:\n",
    "        return best_attr\n",
    "\n",
    "    descr_woe = None\n",
    "    if type_attr == \"woe\" or type_attr == \"categ\":\n",
    "        vals_notna, descr_woe = transform_woe_np(vals_notna, cens_notna)\n",
    "\n",
    "    # find splitting values\n",
    "    uniq_set = np.unique(vals_notna)\n",
    "    if uniq_set.shape[0] > thres_cont_bin_max:\n",
    "        uniq_set = np.quantile(vals_notna, [i / float(thres_cont_bin_max) for i in range(1, thres_cont_bin_max)])\n",
    "    else:\n",
    "        uniq_set = (uniq_set[:-1] + uniq_set[1:]) * 0.5\n",
    "    uniq_set = np.unique(np.round(uniq_set, 3))\n",
    "\n",
    "    index_vals_bin = np.digitize(vals_notna, uniq_set, right=True)\n",
    "\n",
    "    # find global hist by times\n",
    "    na_time_hist, na_cens_hist = get_sa_hists(dur[ind], cens[ind],\n",
    "                                              minlength=max_bin + 1, weights=weights[ind])\n",
    "\n",
    "    r_time_hist, r_cens_hist = get_sa_hists(dur_notna, cens_notna,\n",
    "                                            minlength=max_bin + 1, weights=weights_notna)\n",
    "    l_time_hist = np.zeros_like(r_time_hist, dtype=np.float32)\n",
    "    l_cens_hist = l_time_hist.copy()\n",
    "    \n",
    "    num_nan = ind.sum()\n",
    "    num_r = dur_notna.shape[0]\n",
    "    num_l = 0\n",
    "\n",
    "    if criterion == \"confident\" or criterion == \"confident_weights\":\n",
    "        kmf = KaplanMeier()\n",
    "        if criterion == \"confident_weights\":\n",
    "            kmf.fit(dur, cens, weights=weights)\n",
    "        else:\n",
    "            kmf.fit(dur, cens)\n",
    "        ci = kmf.get_confidence_interval_()\n",
    "        weights_hist = 1 / (ci[1:, 1] - ci[1:, 0] + 1)  # (ci[1:, 1] + ci[1:, 0] + 1e-5)\n",
    "        criterion = \"weights\"\n",
    "    elif criterion == \"fullprob\":\n",
    "        kmf = FullProbKM()\n",
    "        kmf.fit(dur, cens)\n",
    "        weights_hist = kmf.survival_function_at_times(np.unique(dur))\n",
    "        criterion = \"weights\"\n",
    "    elif criterion == \"ibswei\":\n",
    "        kmf = KaplanMeierZeroAfter()\n",
    "        dur_ = arr[2].copy()\n",
    "        kmf.fit(dur_, cens)\n",
    "\n",
    "        dd = np.unique(dur_)\n",
    "        sf = kmf.survival_function_at_times(dd)\n",
    "        sf = np.repeat(sf[np.newaxis, :], dd.shape[0], axis=0)\n",
    "\n",
    "        y_ = get_y(cens=np.ones_like(dd), time=dd)\n",
    "        y_[\"cens\"] = True\n",
    "        ibs_ev = ibs_WW(y_, y_, sf, dd, axis=0)\n",
    "        y_[\"cens\"] = False\n",
    "        ibs_cn = ibs_WW(y_, y_, sf, dd, axis=0)\n",
    "\n",
    "        ratio = np.sum(cens)/cens.shape[0]\n",
    "        weights_hist = ibs_ev*ratio + ibs_cn*(1-ratio)\n",
    "        criterion = \"weights\"\n",
    "    elif criterion == \"T-ET\":\n",
    "        kmf = KaplanMeierZeroAfter()\n",
    "        dur_ = arr[2].copy()\n",
    "        kmf.fit(dur_, cens)\n",
    "\n",
    "        dd = np.unique(dur_)\n",
    "        ET = np.trapz(kmf.survival_function_at_times(dd), dd)\n",
    "        weights_hist = (dd - ET)  # **2\n",
    "        criterion = \"weights\"\n",
    "    elif criterion == \"kde\":\n",
    "        na = NelsonAalen()\n",
    "        na.fit(dur, cens, np.ones(len(dur)))\n",
    "        weights_hist = na.get_smoothed_hazard_at_times(np.unique(dur))\n",
    "        criterion = \"weights\"\n",
    "    elif criterion == \"weights\":\n",
    "        weights_hist = np.bincount(dur, weights=weights,\n",
    "                                   minlength=max_bin + 1)\n",
    "        weights_hist = np.cumsum(weights_hist[::-1])[::-1]  # np.sqrt()\n",
    "\n",
    "        weights_hist = weights_hist / weights_hist.sum()\n",
    "\n",
    "    # for each split values get branches\n",
    "    attr_dicts = []\n",
    "    \n",
    "    for u in np.unique(index_vals_bin):\n",
    "        curr_mask = index_vals_bin == u\n",
    "        curr_n = curr_mask.sum()\n",
    "        curr_time_hist, curr_cens_hist = get_sa_hists(dur_notna[curr_mask], cens_notna[curr_mask],\n",
    "                                                      minlength=max_bin + 1, weights=weights_notna[curr_mask])\n",
    "        l_time_hist += curr_time_hist\n",
    "        l_cens_hist += curr_cens_hist\n",
    "        r_time_hist -= curr_time_hist\n",
    "        r_cens_hist -= curr_cens_hist\n",
    "        num_l += curr_n\n",
    "        num_r -= curr_n\n",
    "\n",
    "        if min(num_l, num_r) <= min_samples_leaf:\n",
    "            continue\n",
    "            \n",
    "#         plt.plot(l_time_hist)\n",
    "#         plt.plot(r_time_hist)\n",
    "#         plt.plot(apr_t_distr)\n",
    "#         plt.show()\n",
    "        \n",
    "        max_stat_val, none_to = optimal_criter_split_hist(\n",
    "            l_time_hist, l_cens_hist, r_time_hist, r_cens_hist,\n",
    "            na_time_hist, na_cens_hist, weights_hist, criterion, dis_coef, \n",
    "            apr_t_distr, apr_e_distr, l_reg)\n",
    "        \n",
    "        if max_stat_val > signif_stat:\n",
    "            attr_loc = get_attrs(max_stat_val, uniq_set[u], none_to, num_l, num_r, num_nan)\n",
    "            attr_dicts.append(attr_loc)\n",
    "            \n",
    "    if len(attr_dicts) == 0:\n",
    "        return best_attr\n",
    "    best_attr = select_best_split_info(attr_dicts, type_attr, bonf, descr_woe=descr_woe)\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print(best_attr[\"p_value\"], len(uniq_set))\n",
    "    return best_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b2516e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from survivors.tree.node import Node, Rule\n",
    "from survivors.tree import CRAID\n",
    "\n",
    "class Node1(Node):\n",
    "    def find_best_split(self):\n",
    "        numb_feats = self.info[\"max_features\"]\n",
    "        numb_feats = np.clip(numb_feats, 1, len(self.features))\n",
    "        n_jobs = min(numb_feats, self.info[\"n_jobs\"])\n",
    "\n",
    "        selected_feats = list(np.random.choice(self.features, size=numb_feats, replace=False))\n",
    "        args = self.get_comb_fast(selected_feats)\n",
    "\n",
    "        ml = np.vectorize(lambda x: hist_best_attr_split(**x))(args)\n",
    "        attrs = {f: ml[ind] for ind, f in enumerate(selected_feats)}\n",
    "        attr = max(attrs, key=lambda x: attrs[x][\"stat_val\"])\n",
    "        \n",
    "        return (attr, attrs[attr])\n",
    "    \n",
    "    def split(self):\n",
    "        node_edges = np.array([], dtype=int)\n",
    "        self.rule_edges = np.array([], dtype=Rule)\n",
    "        \n",
    "        attr, best_split = self.find_best_split()\n",
    "        \n",
    "        # The best split is not significant\n",
    "        if best_split[\"sign_split\"] == 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'Конец ветви, незначащее p-value: {best_split[\"p_value\"]}')\n",
    "            return node_edges\n",
    "        if self.verbose > 0:\n",
    "            print('='*6, best_split[\"p_value\"], attr)\n",
    "\n",
    "        branch_ind = self.ind_for_nodes(self.df[attr], best_split, attr in self.categ)\n",
    "\n",
    "        for n_b in np.unique(branch_ind):\n",
    "            rule = Rule(feature=attr,\n",
    "                        condition=best_split[\"values\"][n_b],\n",
    "                        has_nan=best_split[\"pos_nan\"][n_b])\n",
    "            d_node = self.df[branch_ind == n_b].copy()\n",
    "            N = Node1(df=d_node, full_rule=self.full_rule + [rule],\n",
    "                     features=self.features, categ=self.categ,\n",
    "                     depth=self.depth + 1, verbose=self.verbose, **self.info)\n",
    "            node_edges = np.append(node_edges, N)\n",
    "            self.rule_edges = np.append(self.rule_edges, rule)\n",
    "\n",
    "        if self.rule_edges.shape[0] == 1:\n",
    "            print(branch_ind, self.df[attr], best_split, attr in self.categ)\n",
    "            raise ValueError('ERROR: Only one branch created!')\n",
    "\n",
    "        return node_edges\n",
    "\n",
    "class CRAID1(CRAID):\n",
    "    def fit(self, X, y):\n",
    "        if len(self.features) == 0:\n",
    "            self.features = X.columns\n",
    "        self.bins = cnt.get_bins(time=y[cnt.TIME_NAME])  # , cens = y[cnt.CENS_NAME])\n",
    "        X = X.reset_index(drop=True)\n",
    "        X_tr = X.copy()\n",
    "        X_tr[cnt.CENS_NAME] = y[cnt.CENS_NAME].astype(np.int32)\n",
    "        X_tr[cnt.TIME_NAME] = y[cnt.TIME_NAME].astype(np.float32)\n",
    "\n",
    "        if not (\"min_samples_leaf\" in self.info):\n",
    "            self.info[\"min_samples_leaf\"] = 0.01\n",
    "        if isinstance(self.info[\"min_samples_leaf\"], float):\n",
    "            self.info[\"min_samples_leaf\"] = max(int(self.info[\"min_samples_leaf\"] * X_tr.shape[0]), 1)\n",
    "\n",
    "        cnt.set_seed(self.random_state)\n",
    "\n",
    "        if self.balance in [\"balance\", \"balance+correct\"]:\n",
    "            freq = X_tr[cnt.CENS_NAME].value_counts()\n",
    "            self.correct_proba = freq[1] / (freq[1] + freq[0])  # or freq[1] / (freq[0])\n",
    "\n",
    "            X_tr = get_oversample(X_tr, target=cnt.CENS_NAME)\n",
    "        elif self.balance in [\"balance+weights\"]:\n",
    "            freq = X_tr[cnt.CENS_NAME].value_counts()\n",
    "\n",
    "            X_tr[\"weights_obs\"] = np.where(X_tr[cnt.CENS_NAME], freq[0] / freq[1], 1)\n",
    "            self.info[\"weights_feature\"] = \"weights_obs\"\n",
    "        elif self.balance in [\"only_log_rank\"]:\n",
    "            self.info[\"balance\"] = True\n",
    "\n",
    "        if self.cut:\n",
    "            X_val = X_tr.sample(n=int(0.2 * X_tr.shape[0]), random_state=self.random_state)\n",
    "            X_tr = X_tr.loc[X_tr.index.difference(X_val.index), :]\n",
    "\n",
    "        self.nodes[0] = Node1(X_tr, features=self.features, categ=self.categ, **self.info)\n",
    "        stack_nodes = np.array([0], dtype=int)\n",
    "        while stack_nodes.shape[0] > 0:\n",
    "            node = self.nodes[stack_nodes[0]]\n",
    "            stack_nodes = stack_nodes[1:]\n",
    "            if node.depth >= self.depth:\n",
    "                continue\n",
    "            sub_nodes = node.split()\n",
    "            if sub_nodes.shape[0] > 0:\n",
    "                sub_numbers = np.array([len(self.nodes) + i for i in range(sub_nodes.shape[0])])\n",
    "                for i in range(sub_nodes.shape[0]):\n",
    "                    sub_nodes[i].numb = sub_numbers[i]\n",
    "                self.nodes.update(dict(zip(sub_numbers, sub_nodes)))\n",
    "                node.set_edges(sub_numbers)\n",
    "                stack_nodes = np.append(stack_nodes, sub_numbers)\n",
    "\n",
    "        if self.cut:\n",
    "            self.cut_tree(X_val, cnt.CENS_NAME, mode_f=roc_auc_score, choose_f=max)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "08fea825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BootstrapCRAID1(BootstrapCRAID):\n",
    "    def fit(self, X, y):\n",
    "        self.features = X.columns\n",
    "        X = X.reset_index(drop=True)\n",
    "        X[cnt.CENS_NAME] = y[cnt.CENS_NAME].astype(np.int32)\n",
    "        X[cnt.TIME_NAME] = y[cnt.TIME_NAME].astype(np.float32)\n",
    "\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.update_params()\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            x_sub = self.X_train.sample(n=self.size_sample, replace=self.bootstrap, random_state=i)\n",
    "            x_oob = self.X_train.loc[self.X_train.index.difference(x_sub.index), :]\n",
    "\n",
    "            x_sub = x_sub.reset_index(drop=True)\n",
    "            X_sub_tr, y_sub_cr = cnt.pd_to_xy(x_sub)\n",
    "\n",
    "            model = CRAID1(features=self.features, random_state=i, **self.tree_kwargs)\n",
    "            model.fit(X_sub_tr, y_sub_cr)\n",
    "\n",
    "            self.add_model(model, x_oob)\n",
    "        print(f\"fitted: {len(self.models)} models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "72451b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from survivors.ensemble import BoostingCRAID\n",
    "\n",
    "class IBSCleverBoostingCRAID1(BoostingCRAID):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.name = \"IBSCleverBoostingCRAID\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.features = X.columns\n",
    "        X = X.reset_index(drop=True)\n",
    "        X[cnt.CENS_NAME] = y[cnt.CENS_NAME].astype(np.int32)\n",
    "        X[cnt.TIME_NAME] = y[cnt.TIME_NAME].astype(np.float32)\n",
    "\n",
    "        self.X_train = X\n",
    "        self.X_train[\"ind_start\"] = self.X_train.index\n",
    "        self.y_train = y\n",
    "\n",
    "        self.weights = np.ones(self.X_train.shape[0], dtype=float)\n",
    "        self.bettas = []\n",
    "        self.l_ibs = []\n",
    "        self.l_weights = []\n",
    "        self.update_params()\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            x_sub = self.X_train.sample(n=self.size_sample, \n",
    "                                        # weights=self.weights,\n",
    "                                        replace=self.bootstrap, random_state=i)\n",
    "            \n",
    "            x_oob = self.X_train.loc[self.X_train.index.difference(x_sub.index), :]\n",
    "            print(f\"UNIQUE ({i}):{np.unique(x_sub.index).shape[0]}, DIST:\", np.bincount(x_sub[\"cens\"]))\n",
    "            x_sub = x_sub.reset_index(drop=True)\n",
    "            X_sub_tr, y_sub_tr = cnt.pd_to_xy(x_sub)\n",
    "            if self.weighted_tree:\n",
    "                X_sub_tr[\"weights_obs\"] = self.weights[x_sub['ind_start']]\n",
    "            \n",
    "            model = CRAID1(features=self.features, apr_time=y_sub_tr[\"time\"].copy(), apr_event=y_sub_tr[\"cens\"].copy(),\n",
    "                           random_state=i, **self.tree_kwargs)\n",
    "            model.fit(X_sub_tr, y_sub_tr)\n",
    "\n",
    "            wei_i, betta_i = self.count_model_weights(model, X_sub_tr, y_sub_tr)\n",
    "            self.add_model(model, x_oob, wei_i, betta_i)\n",
    "            self.update_weight(x_sub['ind_start'], wei_i)\n",
    "\n",
    "    def predict(self, x_test, aggreg=True, **kwargs):\n",
    "        res = []\n",
    "        weights = []\n",
    "        for i in range(len(self.models)):\n",
    "            res.append(self.models[i].predict(x_test, **kwargs))\n",
    "\n",
    "        res = np.array(res)\n",
    "        weights = None\n",
    "        if aggreg:\n",
    "            res = self.get_aggreg(res, weights)\n",
    "        return res\n",
    "\n",
    "    def predict_at_times(self, x_test, bins, aggreg=True, mode=\"surv\"):\n",
    "        res = []\n",
    "        weights = []\n",
    "        for i in range(len(self.models)):\n",
    "            res.append(self.models[i].predict_at_times(x_test, bins=bins,\n",
    "                                                       mode=mode))\n",
    "\n",
    "        res = np.array(res)\n",
    "        weights = None\n",
    "        if aggreg:\n",
    "            res = self.get_aggreg(res, weights)\n",
    "            if mode == \"surv\":\n",
    "                res[:, -1] = 0\n",
    "                res[:, 0] = 1\n",
    "        return res\n",
    "\n",
    "    def count_model_weights(self, model, X_sub, y_sub):\n",
    "        if self.all_weight:\n",
    "            X_sub = self.X_train\n",
    "            y_sub = self.y_train\n",
    "        pred_sf = model.predict_at_times(X_sub, bins=self.bins, mode=\"surv\")\n",
    "        \n",
    "        ibs_sf = metr.auprc(self.y_train, y_sub, pred_sf, self.bins, axis=0)\n",
    "        betta = np.mean(ibs_sf)\n",
    "        wei = 1 - ibs_sf\n",
    "        return wei, abs(betta)\n",
    "\n",
    "    def update_weight(self, index, wei_i):\n",
    "        # self.weights += wei_i\n",
    "        pass\n",
    "\n",
    "    def get_aggreg(self, x, wei=None):\n",
    "        if self.aggreg_func == 'median':\n",
    "            return np.median(x, axis=0)\n",
    "        elif self.aggreg_func == \"wei\":\n",
    "            if wei is None:\n",
    "                wei = np.array(self.bettas)\n",
    "            wei = wei / np.sum(wei)\n",
    "            return np.sum((x.T * wei).T, axis=0)\n",
    "        elif self.aggreg_func == \"argmean\":\n",
    "            wei = np.where(np.argsort(np.argsort(wei, axis=1), axis=1) > len(self.bettas)//2, 1, 0)\n",
    "            wei = wei / np.sum(wei, axis=1).reshape(-1, 1)\n",
    "            return np.sum((x.T * wei).T, axis=0)\n",
    "        elif self.aggreg_func == \"argwei\":\n",
    "            wei = np.where(np.argsort(np.argsort(wei, axis=1), axis=1) > len(self.bettas)//2, 1/np.array(self.bettas), 0)\n",
    "            wei = wei / np.sum(wei, axis=1).reshape(-1, 1)\n",
    "            return np.sum((x.T * wei).T, axis=0)\n",
    "        return np.mean(x, axis=0)\n",
    "\n",
    "    def plot_curve(self, X_tmp, y_tmp, bins, label=\"\", metric=\"ibs\"):\n",
    "        res = []\n",
    "        metr_vals = []\n",
    "        for i in range(len(self.models)):\n",
    "            res.append(self.models[i].predict_at_times(X_tmp, bins=bins, mode=\"surv\"))\n",
    "\n",
    "            res_all = np.array(res)\n",
    "            res_all = self.get_aggreg(res_all, np.array(self.bettas)[:i+1])\n",
    "            res_all[:, -1] = 0\n",
    "            res_all[:, 0] = 1\n",
    "            if metric == \"ibs\":\n",
    "                metr_vals.append(metr.ibs_WW(self.y_train, y_tmp, res_all, bins))\n",
    "            else:\n",
    "                metr_vals.append(metr.auprc(self.y_train, y_tmp, res_all, bins))\n",
    "        plt.plot(range(len(self.models)), metr_vals, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0d2564fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: Mean of empty slice\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['mean_' + c] = df_agg[c].apply(np.nanmean)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['min_' + c] = df_agg[c].apply(np.nanmin)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\pandas\\core\\apply.py:1076: RuntimeWarning: All-NaN axis encountered\n",
      "  mapped = lib.map_infer(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['max_' + c] = df_agg[c].apply(np.nanmax)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\datasets\\other.py:111: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_agg['time'] = df_agg.loc[:, ['Admission time', 'Discharge time']].apply(lambda x: (x['Discharge time'] - x['Admission time']).days, axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from survivors.experiments.grid import generate_sample, prepare_sample, count_metric\n",
    "\n",
    "# X, y, features, categ, sch_nan = ds.load_gbsg_dataset()\n",
    "X, y, features, categ, sch_nan = ds.load_wuhan_dataset()\n",
    "# # y[\"time\"] += 1\n",
    "\n",
    "# # y[\"cens\"] = ~y[\"cens\"]\n",
    "# features = list(set(features) - {\"max_2019_nCoV_nucleic_acid_detection\", \n",
    "#                                  \"mean_2019_nCoV_nucleic_acid_detection\", \n",
    "#                                  \"min_2019_nCoV_nucleic_acid_detection\"})\n",
    "# X = X[features]\n",
    "\n",
    "X_TR, X_HO = train_test_split(X, stratify=y[cnt.CENS_NAME],\n",
    "                              test_size=0.33, random_state=42)\n",
    "X_tr, y_tr, X_HO, y_HO, bins_HO = prepare_sample(X, y, X_TR.index, X_HO.index)\n",
    "\n",
    "df = X_HO.copy()\n",
    "df[\"time\"] = y_HO[\"time\"]\n",
    "df[\"cens\"] = y_HO[\"cens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "67d7972a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted: 50 models.\n",
      "[0.1429 0.1375 0.1032 0.1005 0.094  0.0957 0.0878 0.0884 0.0864 0.0851\n",
      " 0.0868 0.0832 0.082  0.0818 0.079  0.0786 0.0788 0.08   0.0786 0.0779\n",
      " 0.0767 0.0773 0.0774 0.0772 0.0764 0.0764 0.076  0.0763 0.0766 0.0765\n",
      " 0.0758 0.0767 0.0766 0.077  0.0767 0.0763 0.0763 0.0764 0.0763 0.0764\n",
      " 0.0765 0.0766 0.0765 0.0756 0.0755 0.0755 0.0754 0.0756 0.0758 0.0757]\n",
      "fitted: 47 models.\n",
      "[0.75551748 0.0749408  0.14910095 0.85885689 0.7424502  0.52176386\n",
      " 0.72907527]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\metrics.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  false_pos = cumsum_fp / n_controls\n"
     ]
    }
   ],
   "source": [
    "from survivors.ensemble import BootstrapCRAID\n",
    "param_bstr = {'balance': None, 'categ': categ, \n",
    "        'criterion': 'peto', 'depth': 10, 'ens_metric_name': 'IBS_REMAIN', \n",
    "        'leaf_model': 'base_zero_after', 'max_features': 0.3, 'min_samples_leaf': 0.01, # 0.01 \n",
    "        'n_estimators': 50, 'n_jobs': 5, 'size_sample': 0.7}\n",
    "\n",
    "\n",
    "bstr = BootstrapCRAID1(**param_bstr)\n",
    "bstr.fit(X_tr, y_tr)\n",
    "bstr.tolerance_find_best(param_bstr[\"ens_metric_name\"])\n",
    "pred_time = bstr.predict(X_HO, target=\"time\")\n",
    "pred_surv = bstr.predict_at_times(X_HO, bins=bins_HO, mode=\"surv\")\n",
    "pred_haz = bstr.predict_at_times(X_HO, bins=bins_HO, mode=\"hazard\")\n",
    "\n",
    "print(count_metric(y_tr, y_HO, pred_time,\n",
    "                   pred_surv, pred_haz, bins_HO, \n",
    "                   ['CI', \"IBS_REMAIN\", \"BAL_IBS_REMAIN\", \"IAUC_WW_TI\", \"AUPRC\", \"EVENT_AUPRC\", \"BAL_AUPRC\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98083547",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.62778972 0.14300061 0.33354884 0.77477676 0.69121148 0.50949231\n",
    " 0.6706261 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.6281024  0.14091349 0.34395037 0.77027241 0.69435691 0.52027288\n",
    " 0.67463645]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ac837",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.62614813 0.14374146 0.34480665 0.75541951 0.69278564 0.51871816\n",
    " 0.67306706]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d68c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.63091655 0.1422004  0.34096467 0.76252518 0.69420142 0.52163777\n",
    " 0.67465319]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.63162009 0.14071645 0.34137235 0.76280546 0.69149669 0.51923545\n",
    " 0.67198272]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2ad4b542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE (0):120, DIST: [93 82]\n",
      "UNIQUE (1):128, DIST: [97 78]\n",
      "UNIQUE (2):126, DIST: [89 86]\n",
      "UNIQUE (3):127, DIST: [94 81]\n",
      "UNIQUE (4):128, DIST: [97 78]\n",
      "UNIQUE (5):126, DIST: [93 82]\n",
      "UNIQUE (6):119, DIST: [94 81]\n",
      "UNIQUE (7):128, DIST: [97 78]\n",
      "UNIQUE (8):128, DIST: [95 80]\n",
      "UNIQUE (9):121, DIST: [96 79]\n",
      "UNIQUE (10):134, DIST: [87 88]\n",
      "UNIQUE (11):118, DIST: [99 76]\n",
      "UNIQUE (12):126, DIST: [83 92]\n",
      "UNIQUE (13):131, DIST: [97 78]\n",
      "UNIQUE (14):123, DIST: [90 85]\n",
      "UNIQUE (15):132, DIST: [94 81]\n",
      "UNIQUE (16):128, DIST: [112  63]\n",
      "UNIQUE (17):128, DIST: [108  67]\n",
      "UNIQUE (18):121, DIST: [90 85]\n",
      "UNIQUE (19):130, DIST: [89 86]\n",
      "UNIQUE (20):127, DIST: [93 82]\n",
      "UNIQUE (21):131, DIST: [106  69]\n",
      "UNIQUE (22):131, DIST: [100  75]\n",
      "UNIQUE (23):121, DIST: [105  70]\n",
      "UNIQUE (24):130, DIST: [91 84]\n",
      "UNIQUE (25):125, DIST: [100  75]\n",
      "UNIQUE (26):124, DIST: [100  75]\n",
      "UNIQUE (27):133, DIST: [90 85]\n",
      "UNIQUE (28):123, DIST: [90 85]\n",
      "UNIQUE (29):127, DIST: [97 78]\n",
      "UNIQUE (30):121, DIST: [96 79]\n",
      "UNIQUE (31):126, DIST: [102  73]\n",
      "UNIQUE (32):130, DIST: [103  72]\n",
      "UNIQUE (33):137, DIST: [86 89]\n",
      "UNIQUE (34):126, DIST: [85 90]\n",
      "UNIQUE (35):125, DIST: [104  71]\n",
      "UNIQUE (36):127, DIST: [104  71]\n",
      "UNIQUE (37):131, DIST: [89 86]\n",
      "UNIQUE (38):130, DIST: [87 88]\n",
      "UNIQUE (39):120, DIST: [96 79]\n",
      "UNIQUE (40):127, DIST: [99 76]\n",
      "UNIQUE (41):126, DIST: [90 85]\n",
      "UNIQUE (42):122, DIST: [100  75]\n",
      "UNIQUE (43):123, DIST: [103  72]\n",
      "UNIQUE (44):131, DIST: [81 94]\n",
      "UNIQUE (45):128, DIST: [98 77]\n",
      "UNIQUE (46):127, DIST: [85 90]\n",
      "UNIQUE (47):118, DIST: [107  68]\n",
      "UNIQUE (48):129, DIST: [83 92]\n",
      "UNIQUE (49):130, DIST: [99 76]\n",
      "[0.1445 0.1307 0.1099 0.1022 0.0946 0.0949 0.0904 0.0929 0.094  0.0911\n",
      " 0.0898 0.0868 0.0831 0.0825 0.0807 0.0806 0.0806 0.0819 0.0802 0.0819\n",
      " 0.0811 0.0821 0.0816 0.0807 0.08   0.0803 0.0803 0.0807 0.0806 0.0796\n",
      " 0.0791 0.0791 0.0787 0.0784 0.0786 0.0788 0.0789 0.0793 0.0789 0.0788\n",
      " 0.0788 0.0782 0.0777 0.0768 0.0765 0.0764 0.0761 0.0762 0.076  0.0756]\n",
      "fitted: 50 models.\n",
      "[0.75517478 0.07205391 0.13473618 0.86944936 0.74515232 0.52232319\n",
      " 0.73164753]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\survive\\lib\\site-packages\\survivors-1.4.4-py3.10.egg\\survivors\\metrics.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  false_pos = cumsum_fp / n_controls\n"
     ]
    }
   ],
   "source": [
    "from survivors.ensemble import BootstrapCRAID\n",
    "param_bstr = {'aggreg_func': 'mean', 'all_weight': True, 'balance': \"only_log_rank\", \n",
    "              'categ': categ, \"l_reg\": 0.01,\n",
    "              'criterion': 'peto', 'depth': 10, 'ens_metric_name': 'IBS_REMAIN', \n",
    "              'leaf_model': 'base_zero_after', 'max_features': 0.3, 'min_samples_leaf': 0.001, # 0.01 \n",
    "              'n_estimators': 50, 'n_jobs': 5, 'size_sample': 0.7}\n",
    "\n",
    "bstr = IBSCleverBoostingCRAID1(**param_bstr)\n",
    "bstr.fit(X_tr, y_tr)\n",
    "bstr.tolerance_find_best(param_bstr[\"ens_metric_name\"])\n",
    "pred_time = bstr.predict(X_HO, target=\"time\")\n",
    "pred_surv = bstr.predict_at_times(X_HO, bins=bins_HO, mode=\"surv\")\n",
    "pred_haz = bstr.predict_at_times(X_HO, bins=bins_HO, mode=\"hazard\")\n",
    "\n",
    "print(count_metric(y_tr, y_HO, pred_time,\n",
    "                   pred_surv, pred_haz, bins_HO, \n",
    "                   ['CI', \"IBS_REMAIN\", \"BAL_IBS_REMAIN\", \"IAUC_WW_TI\", \"AUPRC\", \"EVENT_AUPRC\", \"BAL_AUPRC\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7125dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.75517478 0.07205391 0.13473618 0.86944936 0.74515232 0.52232319\n",
    " 0.73164753]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e354ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.75551748 0.0749408  0.14910095 0.85885689 0.7424502  0.52176386\n",
    " 0.72907527]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eab570",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.62802423 0.14211188 0.34170921 0.75739075 0.69467389 0.51757682\n",
    " 0.67461211]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b294cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.63107289 0.14144822 0.3462126  0.77005228 0.6896938  0.51910505\n",
    " 0.67036929]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.63056478 0.14079638 0.34322143 0.76938389 0.69300919 0.51992004\n",
    " 0.67340143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.63146375 0.14081558 0.34032002 0.76382246 0.6913002  0.51914928\n",
    " 0.67179873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df8e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.62364667 0.14340442 0.34647329 0.77301765 0.69317095 0.51897566\n",
    " 0.67343789]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2128b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.63306625 0.13905343 0.37198661 0.78508546 0.68627601 0.52907648\n",
    " 0.66846826]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.6214188  0.14391302 0.35822151 0.76261641 0.68925319 0.51655777\n",
    " 0.66969004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71db14db",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.63162009 0.14071645 0.34137235 0.76280546 0.69149669 0.51923545\n",
    " 0.67198272]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
