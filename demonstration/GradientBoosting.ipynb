{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7ad35c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalene extension successfully loaded. Note: Scalene currently only\n",
      "supports CPU+GPU profiling inside Jupyter notebooks. For full Scalene\n",
      "profiling, use the command line version.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pathlib, tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from graphviz import Digraph\n",
    "from joblib import Parallel, delayed\n",
    "from scipy import stats\n",
    "\n",
    "from survivors import metrics as metr\n",
    "from survivors import constants as cnt\n",
    "from survivors import criteria as crit\n",
    "from numba import njit, jit, int32, float64\n",
    "from lifelines import KaplanMeierFitter, NelsonAalenFitter\n",
    "\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "%load_ext line_profiler\n",
    "%load_ext scalene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53132903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import survivors.datasets as ds\n",
    "from survivors.tree import CRAID\n",
    "\n",
    "param = {'criterion': 'peto', 'cut': True, 'depth': 10,\n",
    "         'max_features': 1.0, 'min_samples_leaf': 5, \n",
    "         'signif': 0.05}\n",
    "\n",
    "X, y, features, categ, sch_nan = ds.load_pbc_dataset()\n",
    "param[\"categ\"] = categ\n",
    "\n",
    "cr = CRAID(**param)\n",
    "cr.fit(X, y)\n",
    "\n",
    "pred_cens = cr.predict(X, target=\"cens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f1ddb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trt', 'sex', 'ascites', 'hepato', 'spiders']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a04c61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def coxph_negative_gradient(cnp.npy_uint8[:] event,\n",
    "#                             cnp.npy_double[:] time,\n",
    "#                             cnp.npy_double[:] y_pred):\n",
    "#     cdef cnp.npy_double s\n",
    "#     cdef int i\n",
    "#     cdef int j\n",
    "#     cdef cnp.npy_intp n_samples = event.shape[0]\n",
    "\n",
    "#     cdef cnp.ndarray[cnp.npy_double, ndim=1] gradient = cnp.PyArray_EMPTY(1, &n_samples, cnp.NPY_DOUBLE, 0)\n",
    "#     cdef cnp.npy_double[:] exp_tsj = cnp.PyArray_ZEROS(1, &n_samples, cnp.NPY_DOUBLE, 0)\n",
    "\n",
    "#     cdef cnp.npy_double[:] exp_pred = np.exp(y_pred)\n",
    "#     with nogil:\n",
    "#         for i in range(n_samples):\n",
    "#             for j in range(n_samples):\n",
    "#                 if time[j] >= time[i]:\n",
    "#                     exp_tsj[i] += exp_pred[j]\n",
    "\n",
    "#         for i in range(n_samples):\n",
    "#             s = 0\n",
    "#             for j in range(n_samples):\n",
    "#                 if event[j] and time[i] >= time[j]:\n",
    "#                     s += exp_pred[i] / exp_tsj[j]\n",
    "#             gradient[i] = event[i] - s\n",
    "\n",
    "#     return gradient\n",
    "\n",
    "from numba import njit, jit\n",
    "\n",
    "@jit  # ('f8(i8[:], f8[:], f8[:])')\n",
    "def coxph_negative_gradient(event, time, y_pred):\n",
    "    n_samples = event.shape[0]\n",
    "\n",
    "    gradient = np.zeros(n_samples, dtype=float)\n",
    "    exp_tsj = np.zeros(n_samples, dtype=float)\n",
    "\n",
    "    exp_pred = np.exp(y_pred)\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            if time[j] >= time[i]:\n",
    "                exp_tsj[i] += exp_pred[j]\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        s = 0\n",
    "        for j in range(n_samples):\n",
    "            if event[j] and time[i] >= time[j]:\n",
    "                s += exp_pred[i] / exp_tsj[j]\n",
    "        gradient[i] = event[i] - s\n",
    "\n",
    "    return gradient\n",
    "\n",
    "@jit\n",
    "def fast_coxph_negative_gradient(event, time, y_pred):\n",
    "    n_samples = event.shape[0]\n",
    "    r = np.repeat(time[:, np.newaxis], n_samples, axis=1)\n",
    "    exp_pred = np.exp(y_pred)\n",
    "    exp_tsj = exp_pred.dot(r >= r.T)\n",
    "\n",
    "    shared_j = event/exp_tsj\n",
    "    gradient = event - exp_pred*shared_j.dot(r <= r.T)\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d0e9035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 µs ± 4.47 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit coxph_negative_gradient(y[\"cens\"], y[\"time\"], pred_cens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ec3f2b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.98 ms ± 5.39 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fast_coxph_negative_gradient(y[\"cens\"], y[\"time\"], pred_cens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba4d6767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  0.85628939],\n",
       "       [ 0.        ,  0.16470588, -0.93795051],\n",
       "       [ 1.        ,  0.625     ,  0.73621406],\n",
       "       ...,\n",
       "       [ 0.        ,  0.16470588, -0.16909675],\n",
       "       [ 0.        ,  0.16470588, -0.09234032],\n",
       "       [ 0.        ,  0.01724138, -0.13255543]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([y[\"cens\"], pred_cens, grad]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9ed1b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "21e7ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from survivors.metrics import ibs, iauc, ipa, get_survival_func\n",
    "from survivors.constants import get_y\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines import NelsonAalenFitter\n",
    "\n",
    "bins = np.array([1, 10, 100, 1000])\n",
    "\n",
    "y_train = get_y(np.array([1, 0]), np.array([100, 100]))\n",
    "y_test_1 = get_y(np.array([1]), np.array([100]))\n",
    "y_test_2 = get_y(np.array([0]), np.array([100]))\n",
    "y_test_3 = get_y(np.array([1]), np.array([50]))\n",
    "\n",
    "kmf_train = KaplanMeierFitter()\n",
    "kmf_train.fit(y_train['time'], event_observed=y_train['cens'])\n",
    "sf_train = kmf_train.survival_function_at_times(bins).to_numpy()[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "01a61d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23648648648648649"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibs(y_train, y_test_3, sf_train, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "152eb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KaplanMeier:\n",
    "    def __init__(self):\n",
    "        self.timeline = None\n",
    "        self.survival_function = None\n",
    "        self.confidence_interval_ = None\n",
    "        self.alpha = 0.05\n",
    "\n",
    "    def fit(self, durations, right_censor, weights=None):\n",
    "        if weights is None:\n",
    "            weights = np.ones(right_censor.shape)\n",
    "        self.timeline = np.unique(durations)\n",
    "\n",
    "        dur_ = np.searchsorted(self.timeline, durations)\n",
    "        hist_dur = np.bincount(dur_, weights=weights)\n",
    "        self.hist_cens = np.bincount(dur_, weights=right_censor*weights)\n",
    "        self.cumul_hist_dur = np.cumsum(hist_dur[::-1])[::-1]\n",
    "        self.survival_function = np.hstack([1.0, np.cumprod((1.0 - self.hist_cens / (self.cumul_hist_dur)))])\n",
    "\n",
    "    def count_confidence_interval(self):\n",
    "        ''' exponential Greenwood: https://www.math.wustl.edu/~sawyer/handouts/greenwood.pdf '''\n",
    "        z = ss.norm.ppf(1 - self.alpha / 2)\n",
    "        cumulative_sq_ = np.sqrt(np.hstack([0.0, np.cumsum(self.hist_cens / (self.cumul_hist_dur * (self.cumul_hist_dur - self.hist_cens)))]))\n",
    "        np.nan_to_num(cumulative_sq_, copy=False, nan=0)\n",
    "        v = np.log(self.survival_function)\n",
    "        np.nan_to_num(v, copy=False, nan=0)\n",
    "        self.confidence_interval_ = np.vstack([np.exp(v * np.exp(- z * cumulative_sq_ / v)),\n",
    "                                               np.exp(v * np.exp(+ z * cumulative_sq_ / v))]).T\n",
    "        np.nan_to_num(self.confidence_interval_, copy=False, nan=1)\n",
    "\n",
    "    def get_confidence_interval_(self):\n",
    "        if self.confidence_interval_ is None:\n",
    "            self.count_confidence_interval()\n",
    "        return self.confidence_interval_\n",
    "\n",
    "    def survival_function_at_times(self, times):\n",
    "        place_bin = np.digitize(times, self.timeline)\n",
    "        return self.survival_function[np.clip(place_bin, 0, None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "54daebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit()\n",
    "# def _brier_score(ti, t, s, g_t, g_ti, d):\n",
    "#     if (ti <= t) and d == 1:\n",
    "#         return np.power(s, 2) * 1./g_ti\n",
    "#     if ti > t:\n",
    "#         return np.power(1 - s, 2) * 1./g_t\n",
    "#     return 0.\n",
    "\n",
    "@jit()\n",
    "def _brier_score(ti, t, s, g_t, g_ti, d):\n",
    "    return np.where(ti > t, \n",
    "                    np.power(1 - s, 2) * 1./g_t, \n",
    "                    np.where(d == 1, \n",
    "                             np.power(s, 2) * 1./g_ti, \n",
    "                             0.0))\n",
    "\n",
    "def _inverse_censoring_metric(func):\n",
    "    def metric(survival_train, survival_test, estimate, times):\n",
    "        ipcw = KaplanMeier()\n",
    "        ipcw.fit(survival_train[\"time\"], 1 - survival_train[\"cens\"])\n",
    "        g_t = ipcw.survival_function_at_times(times)\n",
    "        g_ti = ipcw.survival_function_at_times(survival_test[\"time\"])\n",
    "        arr = np.zeros_like(estimate, dtype=float)\n",
    "        \n",
    "        for i, t in enumerate(times):\n",
    "            arr[:,i] = func(survival_test[\"time\"], t, estimate[:,i], g_t[i], g_ti, survival_test[\"cens\"])\n",
    "        return arr\n",
    "    return metric\n",
    "\n",
    "def _integrated_metric(func):\n",
    "    def metric(survival_train, survival_test, estimate, times):\n",
    "        scores = func(survival_train, survival_test, estimate, times)\n",
    "        integral = np.trapz(scores, times)\n",
    "        return integral / (times[-1] - times[0])\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "575b042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibs__ = _inverse_censoring_metric(_brier_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "cdc5d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibs_ = _integrated_metric(ibs__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "904f9225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.25 0.25]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.23648649])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibs_(y_train, y_test_3, sf_train, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3cccbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463bb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ac05bc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from survivors.experiments.grid import generate_sample\n",
    "\n",
    "X, y, features, categ, sch_nan = ds.load_pbc_dataset()\n",
    "gen = generate_sample(X, y, 5)\n",
    "X_train, y_train, X_test, y_test, bins = next(gen)\n",
    "\n",
    "cr = CRAID(**param)\n",
    "cr.fit(X_train, y_train)\n",
    "\n",
    "pred_sf = cr.predict_at_times(X_test, bins, mode=\"surv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "d70fcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_hf = cr.predict_at_times(X_test, bins, mode=\"hazard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "1f2be57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.1 ms ± 361 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ibs_(y_train, y_test, pred_sf, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "d45be185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 ms ± 623 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit ibs(y_train, y_test, pred_sf, bins, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "db73bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood(time, cens, sf, cumhf, bins):\n",
    "    index_times = np.digitize(time, bins, right=True) - 1\n",
    "    hf = np.hstack((cumhf[:, 0][np.newaxis].T, np.diff(cumhf)))\n",
    "    sf_by_times = np.take_along_axis(sf, index_times[:, np.newaxis], axis=1)[:, 0] + 1e-10\n",
    "    hf_by_times = (np.take_along_axis(hf, index_times[:, np.newaxis], axis=1)[:, 0] + 1e-10)**cens\n",
    "    likelihood = np.sum(np.log(sf_by_times) + np.log(hf_by_times))\n",
    "    return likelihood\n",
    "\n",
    "def kl(time, cens, sf, cumhf, bins):\n",
    "    index_times = np.digitize(time, bins, right=True) - 1\n",
    "    hf = np.hstack((cumhf[:, 0][np.newaxis].T, np.diff(cumhf)))\n",
    "    sf_by_times = np.take_along_axis(sf, index_times[:, np.newaxis], axis=1)[:, 0] + 1e-10\n",
    "    hf_by_times = (np.take_along_axis(hf, index_times[:, np.newaxis], axis=1)[:, 0] + 1e-10)**cens\n",
    "    likelihood = np.sum(np.log(sf_by_times) + np.log(hf_by_times))\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "220703fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1099.563431516333"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglikelihood(y_test[\"time\"], y_test[\"cens\"], pred_sf, pred_hf, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "6eacb04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ...,  0,  1, 12], dtype=int64)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[\"time\"], bins\n",
    "np.bincount(index_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "bde217cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103.07480247,  87.3916971 ,  36.01652794, 108.36656156,\n",
       "        86.50062991,   0.        ,   5.05844785,  87.3916971 ,\n",
       "        86.50062991,  86.50062991,  36.01652794, 103.07480247,\n",
       "         0.        , 111.14680412,  87.3916971 ,   0.        ,\n",
       "        86.50062991, 103.07480247,  87.3916971 , 103.07480247,\n",
       "        36.01652794,  86.50062991,  86.50062991, 108.36656156,\n",
       "         0.        ,  86.50062991, 103.07480247, 103.07480247,\n",
       "        72.20241692,  86.50062991,  86.50062991, 108.36656156,\n",
       "         0.        ,  87.3916971 ,  87.3916971 ,  72.20241692,\n",
       "       103.07480247,  86.50062991,  36.01652794,  36.01652794,\n",
       "        86.50062991, 108.36656156,  87.3916971 ,  86.50062991,\n",
       "        72.20241692, 103.07480247,   0.        , 108.36656156,\n",
       "        36.01652794,  36.01652794,  87.3916971 ,  87.3916971 ,\n",
       "         0.        ,   0.        ,   5.05844785,   0.        ,\n",
       "        72.20241692,  36.01652794,   0.        ,  68.7309792 ,\n",
       "        68.7309792 ,  36.01652794,   0.        ,   0.        ,\n",
       "        87.3916971 ,   5.05844785,  87.3916971 , 108.36656156,\n",
       "         0.        ,   0.        ,   5.05844785,  68.7309792 ,\n",
       "         0.        ,  86.50062991,   0.        ,  86.50062991,\n",
       "        86.50062991,   0.        ,  36.01652794,  36.01652794,\n",
       "        68.7309792 ,   0.        , 108.36656156,   0.        ])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_times = np.digitize(y_test[\"time\"], bins, right=True) - 1\n",
    "arr = np.zeros_like(pred_hf, dtype=int)\n",
    "arr[np.arange(arr.shape[0]), index_times] = 1\n",
    "hf = np.hstack((pred_hf[:, 0][np.newaxis].T, np.diff(pred_hf)))\n",
    "\n",
    "np.sum(hf * np.log((hf + 1e-20)/(arr + 1e-20)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a44af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
