{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0057c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pathlib, tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from graphviz import Digraph\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from survivors.tree.find_split import best_attr_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "\n",
    "from survivors import metrics as metr\n",
    "from survivors import constants as cnt\n",
    "\n",
    "from survivors.tree import CRAID\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa00f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\" Auxiliary functions \"\"\"\n",
    "def join_dict(a, b):\n",
    "    return dict(list(a.items()) + list(b.items()))\n",
    "\n",
    "\n",
    "class LeafModel(object):\n",
    "    def __init__(self):\n",
    "        self.survival = None\n",
    "        self.hazard = None\n",
    "        self.features_mean = dict()\n",
    "\n",
    "    def fit(self, X_node):\n",
    "        self.survival = metr.get_survival_func(X_node[cnt.TIME_NAME], X_node[cnt.CENS_NAME])\n",
    "        self.hazard = metr.get_hazard_func(X_node[cnt.TIME_NAME], X_node[cnt.CENS_NAME])\n",
    "        self.features_mean = X_node.mean(axis=0).to_dict()\n",
    "\n",
    "    def predict_mean_feature(self, X, feature_name):\n",
    "        return self.features_mean[feature_name]\n",
    "\n",
    "    def predict_survival_at_times(self, X, bins):\n",
    "        return self.survival.survival_function_at_times(bins).to_numpy()\n",
    "\n",
    "    def predict_hazard_at_times(self, X, bins):\n",
    "        return self.survival.cumulative_hazard_at_times(bins).to_numpy()\n",
    "\n",
    "\n",
    "\"\"\" Класс вершины дерева решений \"\"\"\n",
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Node of decision tree.\n",
    "    Allow to separate data into 2 subnodes (references store in edges) \n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "        Data of Node\n",
    "    numb : int\n",
    "        Number or name of Node\n",
    "    depth : int\n",
    "        Distance from root node\n",
    "    edges : array-like\n",
    "        Subbranches after separating\n",
    "    features : list\n",
    "        Available features\n",
    "    categ : list\n",
    "        Names of categorical features\n",
    "    woe : boolean\n",
    "        Mode of categorical preparation\n",
    "    rule : dict\n",
    "        Allow to define data to node.\n",
    "        name: str\n",
    "            query in pandas terms\n",
    "        attr: str\n",
    "            feature of separation\n",
    "        pos_nan: int\n",
    "            Indicator of nan\n",
    "    is_leaf : boolean\n",
    "        True if node don't have subnodes\n",
    "    verbose : int\n",
    "        Print best split of node\n",
    "    info : dict\n",
    "        Parameters for finding the best split\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    check_params : Fill empty parameters and map max_features to int\n",
    "    find_best_split : Choose best split of node according to parameters\n",
    "    split : Try to create subnodes by best split\n",
    "    get_df_node : Return data for node\n",
    "    set_leaf : Delete subnodes and reset data\n",
    "    \n",
    "    predict : Return statistic values of data\n",
    "    predict_rules : Return full rules from node to leaf\n",
    "    predict_scheme : Return all possible outcomes for additional features determination\n",
    "    \n",
    "    get_figure : Create picture of data (hist, survival function)\n",
    "    get_rule : Return rule of node\n",
    "    get_description : Return common values of data (size, depth, death, cens)\n",
    "    build_viz : Create and fill graphviz digraph\n",
    "    translate : Replace rules and features by dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    __slots__ = (\"df\", \"numb\",\n",
    "                 \"depth\", \"edges\", \"features\", \"leaf_model\",\n",
    "                 \"categ\", \"woe\", \"rule\", \"is_leaf\", \"verbose\", \"info\")\n",
    "\n",
    "    def __init__(self, df,  numb=1, depth=0,\n",
    "                 features=[], categ=[], woe=False,\n",
    "                 rule={\"name\": \"\", \"attr\": \"\", \"pos_nan\": 0},\n",
    "                 verbose=0, **info):\n",
    "        self.df = df\n",
    "        self.numb = numb\n",
    "        self.depth = depth\n",
    "        self.edges = np.array([])\n",
    "        self.features = features\n",
    "        self.categ = categ\n",
    "        self.woe = woe\n",
    "        self.rule = rule\n",
    "        self.is_leaf = True\n",
    "        self.verbose = verbose\n",
    "        self.info = info\n",
    "        self.leaf_model = LeafModel()\n",
    "        self.check_params()\n",
    "    \n",
    "    def check_params(self):\n",
    "        self.info.setdefault(\"bonf\", True)\n",
    "        self.info.setdefault(\"n_jobs\", 16)\n",
    "        self.info.setdefault(\"max_features\", 1.0)\n",
    "        self.info.setdefault(\"signif\", 1.1)\n",
    "        self.info.setdefault(\"thres_cont_bin_max\", 100)\n",
    "        if self.info[\"max_features\"] == \"sqrt\":\n",
    "            self.info[\"max_features\"] = int(np.trunc(np.sqrt(len(self.features))+0.5))\n",
    "        elif isinstance(self.info[\"max_features\"], float):\n",
    "            self.info[\"max_features\"] = int(self.info[\"max_features\"]*len(self.features))\n",
    "        self.leaf_model.fit(self.df)\n",
    "\n",
    "    \"\"\" GROUP FUNCTIONS: CREATE LEAFS \"\"\"\n",
    "    \n",
    "    def find_best_split(self):\n",
    "        numb_feats = self.info[\"max_features\"]\n",
    "        numb_feats = np.clip(numb_feats, 1, len(self.features))\n",
    "        n_jobs = min(numb_feats, self.info[\"n_jobs\"])\n",
    "        selected_feats = np.random.choice(self.features, size=numb_feats, replace=False)\n",
    "        \n",
    "        args = np.array([])\n",
    "        for feat in selected_feats:\n",
    "            t = self.info.copy()\n",
    "            t[\"type_attr\"] = \"woe\" if self.woe else \"categ\" if feat in self.categ else \"cont\"\n",
    "            t[\"arr\"] = self.df.loc[:, [feat, cnt.CENS_NAME, cnt.TIME_NAME]].to_numpy().T\n",
    "            args = np.append(args, t)\n",
    "        with Parallel(n_jobs=n_jobs, verbose=0, batch_size=10) as parallel:\n",
    "            ml = parallel(delayed(best_attr_split)(**a) for a in args)\n",
    "\n",
    "        attrs = {f: ml[ind] for ind, f in enumerate(selected_feats)}\n",
    "        attr = min(attrs, key=lambda x: attrs[x][\"p_value\"])\n",
    "        \n",
    "        if attrs[attr][\"sign_split\"] > 0 and self.info[\"bonf\"]:\n",
    "            attrs[attr][\"p_value\"] = attrs[attr][\"p_value\"] / attrs[attr][\"sign_split\"]\n",
    "        return (attr, attrs[attr])\n",
    "        \n",
    "    def split(self):\n",
    "        node_edges = np.array([], dtype = object)\n",
    "        attr, best_split = self.find_best_split()\n",
    "        # В лучшем признаке не было ни одного значимого разбиения\n",
    "        if best_split[\"sign_split\"] == 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'Конец ветви, незначащее p-value: {best_split[\"p_value\"]}')\n",
    "            return (attr, best_split)\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print('='*6, best_split[\"p_value\"], attr)\n",
    "        leaf_ind = 0\n",
    "        for v, p_n in zip(best_split[\"values\"], best_split[\"pos_nan\"]):\n",
    "            query = attr + v\n",
    "            if p_n == 1:\n",
    "                query = \"(\" + attr + v + \") or (\" + attr + \" != \" + attr + \")\"\n",
    "            d_node = self.df.query(query).copy()\n",
    "            N = Node(df=d_node,\n",
    "                     features=self.features, categ=self.categ, depth=self.depth+1, \n",
    "                     rule={\"name\": attr + v, \"attr\": attr, \"pos_nan\": p_n},\n",
    "                     verbose=self.verbose, **self.info)\n",
    "            node_edges = np.append(node_edges, N)\n",
    "        return node_edges\n",
    "        \n",
    "    def set_edges(self, edges):\n",
    "        self.edges = edges\n",
    "        self.is_leaf = False\n",
    "        self.df = None\n",
    "        \n",
    "    \"\"\" GROUP FUNCTIONS: CLEAR AND DEL \"\"\"\n",
    "    def get_df_node(self):\n",
    "        if self.is_leaf:\n",
    "            return self.df\n",
    "        return pd.concat([edge.get_df_node() for edge in self.edges])\n",
    "    \n",
    "    def set_leaf(self):\n",
    "        if self.is_leaf:\n",
    "            return\n",
    "        self.df = self.get_df_node()\n",
    "        del self.edges\n",
    "        self.edges = np.array([])\n",
    "        self.is_leaf = True\n",
    "\n",
    "    def prepare_df_for_attr(self, X):\n",
    "        attr = self.edges[0].rule['attr']\n",
    "        if attr not in X.columns:\n",
    "            X.loc[:, attr] = np.nan\n",
    "        return X\n",
    "\n",
    "    def get_split_nan_index(self, X):\n",
    "        ind_nan = X.index\n",
    "        for edge in self.edges:\n",
    "            ind_nan = ind_nan.difference(X.query(edge.rule[\"name\"]).index)\n",
    "        return ind_nan\n",
    "        \n",
    "    \"\"\" GROUP FUNCTIONS: PREDICT \"\"\"\n",
    "        \n",
    "    def predict(self, X, target, name_tg=\"res\", bins=None, end_list=[]):\n",
    "        \"\"\"\n",
    "        Return statistic values of data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Pandas dataframe\n",
    "            Contain input features of events.\n",
    "        target : str or function\n",
    "            Column name, mode or aggregate function of leaf sample.\n",
    "            Column name : must be in dataset.columns\n",
    "                Return mean of feature\n",
    "            Mode :\n",
    "                \"surv\" return survival function\n",
    "                \"hazard\" return cumulative hazard function\n",
    "                \"depth\" return leafs depth\n",
    "                \"num_node\" return leafs numb (names)\n",
    "        bins : array-like\n",
    "            Points of timeline\n",
    "        name_tg : str, optional\n",
    "            Name of return column. The default is \"res\".\n",
    "        end_list : list, optional\n",
    "            Numbers of end node (instead leaf). The default is [].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X[name_tg] : array-like \n",
    "            Values by target\n",
    "\n",
    "        \"\"\"\n",
    "        if (self.numb in end_list) or self.is_leaf:\n",
    "            if target == \"surv\" or target == \"hazard\":\n",
    "                if target == \"surv\":\n",
    "                    func_at_times = self.leaf_model.predict_survival_at_times(X, bins)  # target(X_node=dataset)\n",
    "                else:\n",
    "                    func_at_times = self.leaf_model.predict_hazard_at_times(X, bins)\n",
    "                X.loc[:, name_tg] = X[name_tg].apply(lambda x: func_at_times)\n",
    "            elif target == \"depth\":\n",
    "                X.loc[:, name_tg] = self.depth\n",
    "            elif target == \"num_node\":\n",
    "                X.loc[:, name_tg] = self.numb\n",
    "            else:\n",
    "                dataset = self.get_df_node()\n",
    "                if target in dataset.columns:\n",
    "                    X.loc[:, name_tg] = self.leaf_model.predict_mean_feature(X, target)  # np.mean(dataset[target])\n",
    "        else:\n",
    "            X = self.prepare_df_for_attr(X)\n",
    "            ind_nan = self.get_split_nan_index(X)\n",
    "                \n",
    "            for edge in self.edges:\n",
    "                ind = X.query(edge.rule[\"name\"]).index\n",
    "                if edge.rule[\"pos_nan\"] == 1:\n",
    "                    ind = ind.append(ind_nan)\n",
    "                if len(ind) > 0:\n",
    "                    X.loc[ind, name_tg] = edge.predict(X=X.loc[ind, :], target=target, bins=bins,\n",
    "                                                       name_tg=name_tg, end_list=end_list)\n",
    "        return X[name_tg]\n",
    "    \n",
    "    def predict_rules(self, X, name_tg=\"res\"):\n",
    "        if self.is_leaf:\n",
    "            X.loc[:, name_tg] = self.get_rule()\n",
    "        else:\n",
    "            X = self.prepare_df_for_attr(X)\n",
    "            ind_nan = self.get_split_nan_index(X)\n",
    "\n",
    "            for edge in self.edges:\n",
    "                ind = X.query(edge.rule[\"name\"]).index\n",
    "                if edge.rule[\"pos_nan\"] == 1:\n",
    "                    ind = ind.append(ind_nan)\n",
    "                if len(ind) > 0:\n",
    "                    X.loc[ind, name_tg] = edge.predict_rules(X.loc[ind, :], name_tg)\n",
    "                    if len(self.rule[\"name\"]) > 0:\n",
    "                        X.loc[ind, name_tg] = self.get_rule() + '&' + X.loc[ind, name_tg]\n",
    "        return X[name_tg]\n",
    "    \n",
    "    def get_values_column(self, columns):\n",
    "        return [0, 1]\n",
    "    \n",
    "    def predict_scheme(self, X, scheme_feat):\n",
    "        \"\"\"\n",
    "        Return all possible outcomes for additional features determination\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Pandas dataframe\n",
    "            Contain input features of events.\n",
    "        scheme_feat : list\n",
    "            Features with missing values (relatively).\n",
    "            If feature in list was used in node, \n",
    "                then node consider all possible replaces for value in branches\n",
    "                Thus, method allow to return all outcomes for different values\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X['res'] : array-like\n",
    "            For each observation contain dict\n",
    "                key : rule of overdefined feature (; is separator)\n",
    "                value : list of sample values\n",
    "                    censoring flag, time, all values for scheme_feat\n",
    "                    \n",
    "        \"\"\"\n",
    "        def scheme_output_format(r):\n",
    "            to_array = lambda col: np.array(self.df.get(col))\n",
    "            return {r['store_str']:\n",
    "                    [to_array(cnt.CENS_NAME), \n",
    "                     to_array(cnt.TIME_NAME), \n",
    "                     # to_array(self.info[\"sum\"]), # TODO FOR SCHEME'S SUM\n",
    "                     {sch: to_array(sch) for sch in scheme_feat}]}\n",
    "            \n",
    "        def join_scheme_leafs(X_sub, ind_nan=[]):\n",
    "            for edge in self.edges:\n",
    "                ind = X_sub.query(edge.rule['name']).index\n",
    "                if len(ind_nan) > 0:\n",
    "                    if edge.rule[\"pos_nan\"] == 1:\n",
    "                        ind = ind.append(ind_nan)\n",
    "                if len(ind) > 0:\n",
    "                    X_sub.loc[ind, 'tmp'] = edge.predict_scheme(X_sub.loc[ind, :], scheme_feat)\n",
    "                    X_sub.loc[ind, 'res'] = X_sub.loc[ind, :].apply(lambda r: join_dict(r['res'], r['tmp']), axis=1)\n",
    "            return X_sub['res']\n",
    "            \n",
    "        if self.is_leaf:\n",
    "            return X.apply(scheme_output_format, axis=1)\n",
    "        attr = self.edges[0].rule['attr']\n",
    "        X = self.prepare_df_for_attr(X)\n",
    "        ind_nan = self.get_split_nan_index(X)\n",
    "        ind_has = X.index.difference(ind_nan)\n",
    "        if attr not in scheme_feat:\n",
    "            X.loc[:, 'res'] = join_scheme_leafs(X, ind_nan)\n",
    "        else:\n",
    "            if len(ind_has) > 0:\n",
    "                X.loc[ind_has, 'res'] = join_scheme_leafs(X.loc[ind_has, :])\n",
    "            if len(ind_nan) > 0:\n",
    "                pred_store = X.loc[ind_nan, 'store_str'].copy()\n",
    "                for val in self.get_values_column(attr):\n",
    "                    X.loc[ind_nan, attr] = val\n",
    "                    X.loc[ind_nan, 'store_str'] = pred_store + attr + '==' + str(val) + ';'\n",
    "                    X.loc[ind_nan, 'res'] = join_scheme_leafs(X.loc[ind_nan, :])\n",
    "        return X['res']\n",
    "    \n",
    "    \"\"\" GROUP FUNCTIONS: VISUALIZATION \"\"\"\n",
    "    \n",
    "    def get_figure(self, mode=\"hist\", target=None, save_path=\"\"):\n",
    "        if len(save_path) > 0:\n",
    "            plt.ioff()\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        local_df = self.get_df_node()\n",
    "        if mode == \"hist\":\n",
    "            local_df[target].hist(bins=25)\n",
    "            ax.set_xlim([0, np.max(local_df[target])])\n",
    "        elif mode == \"surv\":\n",
    "            kmf = metr.get_survival_func(local_df[cnt.TIME_NAME], local_df[cnt.CENS_NAME])\n",
    "            ax.set_xlim([0, np.max(local_df[cnt.TIME_NAME])])\n",
    "            ax.set_ylim([0, 1])\n",
    "            plt.xticks(range(0, np.max(local_df[cnt.TIME_NAME])+1, 1000))\n",
    "            kmf.plot_survival_function(legend=False, fontsize=25)\n",
    "            # ax.set_xlabel('Время', fontsize=25)\n",
    "            # ax.set_ylabel('Вероятность выживания', fontsize=25)\n",
    "            ax.set_xlabel('Time', fontsize=25)\n",
    "            ax.set_ylabel('Survival probability', fontsize=25)  # plt.xlabel('Timeline', fontsize=0)\n",
    "        if len(save_path) > 0:\n",
    "            plt.savefig(save_path)\n",
    "        else:\n",
    "            plt.show()\n",
    "    \n",
    "    def get_rule(self):\n",
    "        if not(self.rule[\"pos_nan\"]):\n",
    "            return f'({self.rule[\"name\"]})'\n",
    "        # return f'(({self.rule[\"name\"]})|({self.rule[\"attr\"]} != {self.rule[\"attr\"]}))'\n",
    "        return f'(({self.rule[\"name\"]})| не указано)'\n",
    "    \n",
    "    def get_description(self, full=False):\n",
    "        s = \"\"  # if not(self.rule[\"pos_nan\"]) else \" or \" + self.rule[\"attr\"] + \" == NaN\"\n",
    "        d = self.get_df_node()\n",
    "        m_cens = round(d[cnt.CENS_NAME].mean(), 2)\n",
    "        m_time = round(d[cnt.TIME_NAME].mean(), 2)\n",
    "        if full:\n",
    "            label = \"\\n\".join([self.rule[\"name\"] + s,\n",
    "                               \"size = %s\" % (d.shape[0]),\n",
    "                               \"cens/size = %s\" % (m_cens),\n",
    "                               \"depth = %s\" % (self.depth),\n",
    "                               \"death = %s\" % (m_time)])\n",
    "        else:\n",
    "            label = self.rule[\"name\"] + s \n",
    "        return label\n",
    "        \n",
    "    def build_viz(self, dot=None, path_dir=\"\", depth=None, **args):\n",
    "        if dot is None:\n",
    "            dot = Digraph()\n",
    "        img_path = path_dir + str(self.numb) + '.png'\n",
    "        self.get_figure(save_path=img_path, **args)\n",
    "        dot.node(str(self.numb), label=self.get_description(),\n",
    "                 image=img_path, fontsize='30')  # fontsize='16'\n",
    "        if not(depth is None):\n",
    "            if depth < self.depth:\n",
    "                return dot\n",
    "        for ind_e in range(self.edges.shape[0]):\n",
    "            dot = self.edges[ind_e].build_viz(dot, path_dir, **args)\n",
    "            dot.edge(str(self.numb), str(self.edges[ind_e].numb))\n",
    "        return dot\n",
    "         \n",
    "    def translate(self, describe):\n",
    "        if self.is_leaf:\n",
    "            self.df = self.df.rename(describe, axis=1)\n",
    "        self.features = [describe.get(f, f) for f in self.features]\n",
    "        self.categ = [describe.get(c, c) for c in self.categ]\n",
    "        self.rule[\"name\"] = describe.get(self.rule[\"name\"], self.rule[\"name\"])\n",
    "        for edge in self.edges:\n",
    "            edge.translate(describe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2616b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_pandas(X, columns):\n",
    "    type_df = type(X)\n",
    "    if type_df.__name__ == \"DataFrame\":\n",
    "        return X.loc[:,columns]\n",
    "    elif type_df.__name__ == \"ndarray\":\n",
    "        return pd.DataFrame(X, columns = columns)\n",
    "    return None\n",
    "\n",
    "\"\"\" Functions of prunning \"\"\"\n",
    "\n",
    "def ols(a,b):\n",
    "    return sum((a - b)**2)\n",
    "\n",
    "def find_best_uncut(tree, X, y, target, mode_f, choose_f):\n",
    "    span_leaf = tree.get_spanning_leaf_numbers()\n",
    "    d = {}\n",
    "    for el in span_leaf:\n",
    "        y_pred = tree.predict(X, target = target, end_list = [el])\n",
    "        d[el] = round(mode_f(y,y_pred),4)\n",
    "    \n",
    "    new_leaf, val = choose_f(d.items(), key = lambda x: x[1])\n",
    "    tree.delete_leafs_by_span([new_leaf])\n",
    "    return tree, val\n",
    "    \n",
    "def cutted_tree(tree_, X, target, mode_f, choose_f, verbose = 0):\n",
    "    first_digits = lambda x: float(str(x)[:5])\n",
    "    y = pd.to_numeric(X[target])\n",
    "    tree = copy.deepcopy(tree_)\n",
    "    best_metr = dict()\n",
    "    best_tree = dict()\n",
    "    y_pred = tree.predict(X, target = target)\n",
    "    c = tree.get_leaf_numbers().shape[0]\n",
    "    \n",
    "    best_metr[c] = mode_f(y, y_pred)\n",
    "    best_tree[c] = copy.deepcopy(tree)\n",
    "    while (len(tree.nodes) > 1):\n",
    "        tree, val = find_best_uncut(tree, X, y, target, mode_f, choose_f)\n",
    "        c = tree.get_leaf_numbers().shape[0]\n",
    "        best_metr[c] = val\n",
    "        best_tree[c] = copy.deepcopy(tree)\n",
    "    \n",
    "    best_metric = first_digits(choose_f(best_metr.values()))\n",
    "    min_leaf = min([k for k,v in best_metr.items() if first_digits(v) == best_metric])\n",
    "    \n",
    "    if verbose > 0:\n",
    "        plt.clf()\n",
    "        plt.plot(list(best_metr.keys()), list(best_metr.values()), 'o')\n",
    "        # plt.plot(list(best_metr.keys()), list(best_metr.values()), 'b')\n",
    "        plt.xlabel(\"Количество листов\")  # (\"Leafs\")\n",
    "        plt.ylabel(f\"Лучшее значение метрики {mode_f.__name__}\")  # {target}\")\n",
    "        plt.title(f\"Обрезка дерева по переменной {target}\")\n",
    "        plt.show()\n",
    "        print(best_metr)\n",
    "        print(best_metric, min_leaf)\n",
    "    \n",
    "    return best_tree[min_leaf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e547ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ec33cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\" Auxiliary functions \"\"\"\n",
    "def join_dict(a, b):\n",
    "    return dict(list(a.items()) + list(b.items()))\n",
    "\n",
    "def rule_to_string(r):\n",
    "    s = f\"({r['attr']}{r['name']})\"\n",
    "    if r[\"pos_nan\"]:\n",
    "        s = f\"({s}| nan)\"  # не указано)\"\n",
    "    return s\n",
    "\n",
    "\n",
    "class LeafModel(object):\n",
    "    def __init__(self):\n",
    "        self.shape = None\n",
    "        self.survival = None\n",
    "        self.hazard = None\n",
    "        self.features_mean = dict()\n",
    "\n",
    "    def fit(self, X_node, need_features=[cnt.TIME_NAME, cnt.CENS_NAME]):\n",
    "        self.shape = X_node.shape\n",
    "        self.default_bins = cnt.get_bins(time=X_node[cnt.TIME_NAME].to_numpy(), \n",
    "                                         cens=X_node[cnt.CENS_NAME].to_numpy(), mode='a', num_bins=100)\n",
    "        self.survival = metr.get_survival_func(X_node[cnt.TIME_NAME], X_node[cnt.CENS_NAME])\n",
    "        self.hazard = metr.get_hazard_func(X_node[cnt.TIME_NAME], X_node[cnt.CENS_NAME])\n",
    "        self.features_mean = X_node.mean(axis=0).to_dict()\n",
    "        self.lists = X_node.loc[:, need_features].to_dict(orient=\"list\")\n",
    "\n",
    "    def get_shape(self):\n",
    "        return self.shape\n",
    "    \n",
    "    def predict_list_feature(self, feature_name):\n",
    "        if feature_name in self.lists.keys():\n",
    "            return self.lists[feature_name]\n",
    "        return None\n",
    "        \n",
    "    def predict_mean_feature(self, X, feature_name):\n",
    "        return self.features_mean[feature_name]\n",
    "\n",
    "    def predict_survival_at_times(self, X, bins=None):\n",
    "        if bins is None:\n",
    "            bins = self.default_bins\n",
    "        return self.survival.survival_function_at_times(bins).to_numpy()\n",
    "\n",
    "    def predict_hazard_at_times(self, X, bins=None):\n",
    "        if bins is None:\n",
    "            bins = self.default_bins\n",
    "        return self.survival.cumulative_hazard_at_times(bins).to_numpy()\n",
    "\n",
    "\n",
    "class Rule(object):\n",
    "    def __init__(self, feature : str, condition : str, has_nan : int):\n",
    "        self.feature = feature\n",
    "        self.condition = condition\n",
    "        self.has_nan_ = has_nan\n",
    "        \n",
    "    def get_feature(self):\n",
    "        return self.feature\n",
    "    \n",
    "    def get_condition(self):\n",
    "        return self.condition\n",
    "    \n",
    "    def has_nan(self):\n",
    "        return self.has_nan_\n",
    "    \n",
    "    def translate(self, describe):\n",
    "        self.feature = describe.get(self.feature, self.feature)\n",
    "    \n",
    "    def to_str(self):\n",
    "        s = f\"({self.feature}{self.condition})\"\n",
    "        if self.has_nan_:\n",
    "            s = f\"({s}| nan)\"  # не указано)\"\n",
    "        return s\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\"\"\" Класс вершины дерева решений \"\"\"\n",
    "class Node(object):\n",
    "    __slots__ = (\"df\", \"numb\",\n",
    "                 \"depth\", \"edges\", \"rule_edges\", \"features\", \"leaf_model\",\n",
    "                 \"categ\", \"woe\", \"is_leaf\", \"verbose\", \"info\")\n",
    "\n",
    "    def __init__(self, df,  numb=0, depth=0,\n",
    "                 features=[], categ=[], woe=False,\n",
    "                 verbose=0, **info):\n",
    "        self.df = df\n",
    "        self.numb = numb\n",
    "        self.depth = depth\n",
    "        self.edges = np.array([], dtype = object)\n",
    "        self.rule_edges = np.array([], dtype = object)\n",
    "        self.features = features\n",
    "        self.categ = categ\n",
    "        self.woe = woe\n",
    "        self.is_leaf = True\n",
    "        self.verbose = verbose\n",
    "        self.info = info\n",
    "        self.leaf_model = LeafModel()\n",
    "        self.check_params()\n",
    "    \n",
    "    def check_params(self):\n",
    "        self.info.setdefault(\"bonf\", True)\n",
    "        self.info.setdefault(\"n_jobs\", 16)\n",
    "        self.info.setdefault(\"max_features\", 1.0)\n",
    "        self.info.setdefault(\"signif\", 1.1)\n",
    "        self.info.setdefault(\"thres_cont_bin_max\", 100)\n",
    "        if self.info[\"max_features\"] == \"sqrt\":\n",
    "            self.info[\"max_features\"] = int(np.trunc(np.sqrt(len(self.features))+0.5))\n",
    "        elif isinstance(self.info[\"max_features\"], float):\n",
    "            self.info[\"max_features\"] = int(self.info[\"max_features\"]*len(self.features))\n",
    "        self.leaf_model.fit(self.df)\n",
    "\n",
    "    \"\"\" GROUP FUNCTIONS: CREATE LEAFS \"\"\"\n",
    "    \n",
    "    def find_best_split(self):\n",
    "        numb_feats = self.info[\"max_features\"]\n",
    "        numb_feats = np.clip(numb_feats, 1, len(self.features))\n",
    "        n_jobs = min(numb_feats, self.info[\"n_jobs\"])\n",
    "        selected_feats = np.random.choice(self.features, size=numb_feats, replace=False)\n",
    "        \n",
    "        args = np.array([])\n",
    "        for feat in selected_feats:\n",
    "            t = self.info.copy()\n",
    "            t[\"type_attr\"] = (\"woe\" if self.woe else \"categ\") if feat in self.categ else \"cont\"\n",
    "            t[\"arr\"] = self.df.loc[:, [feat, cnt.CENS_NAME, cnt.TIME_NAME]].to_numpy().T\n",
    "            args = np.append(args, t)\n",
    "        with Parallel(n_jobs=n_jobs, verbose=0, batch_size=10) as parallel:\n",
    "            ml = parallel(delayed(best_attr_split)(**a) for a in args)\n",
    "\n",
    "        attrs = {f: ml[ind] for ind, f in enumerate(selected_feats)}\n",
    "        attr = min(attrs, key=lambda x: attrs[x][\"p_value\"])\n",
    "        \n",
    "        if attrs[attr][\"sign_split\"] > 0 and self.info[\"bonf\"]:\n",
    "            attrs[attr][\"p_value\"] = attrs[attr][\"p_value\"] / attrs[attr][\"sign_split\"]\n",
    "        return (attr, attrs[attr])\n",
    "        \n",
    "    def split(self):\n",
    "        node_edges = np.array([], dtype = object)\n",
    "        self.rule_edges = np.array([], dtype = object)\n",
    "        \n",
    "        attr, best_split = self.find_best_split()\n",
    "        # The best split is not significant\n",
    "        if best_split[\"sign_split\"] == 0:\n",
    "            if self.verbose > 0:\n",
    "                print(f'Конец ветви, незначащее p-value: {best_split[\"p_value\"]}')\n",
    "            return node_edges\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print('='*6, best_split[\"p_value\"], attr)\n",
    "        for v, p_n in zip(best_split[\"values\"], best_split[\"pos_nan\"]):\n",
    "            query = attr + v\n",
    "            if p_n == 1:\n",
    "                query = \"(\" + attr + v + \") or (\" + attr + \" != \" + attr + \")\"\n",
    "            rule = Rule(feature=attr, condition=v, has_nan=p_n)\n",
    "            d_node = self.df.query(query).copy()\n",
    "            N = Node(df=d_node, features=self.features, categ=self.categ, \n",
    "                     depth=self.depth+1, verbose=self.verbose, **self.info)\n",
    "            node_edges = np.append(node_edges, N)\n",
    "            self.rule_edges = np.append(self.rule_edges, rule)\n",
    "            \n",
    "        return node_edges\n",
    "    \n",
    "    def set_edges(self, edges):\n",
    "        self.edges = edges\n",
    "        self.is_leaf = False\n",
    "        self.df = None\n",
    "        \n",
    "    def set_leaf(self):\n",
    "        if self.is_leaf:\n",
    "            return\n",
    "        self.edges = np.array([])\n",
    "        self.is_leaf = True\n",
    "    \n",
    "    def prepare_df_for_attr(self, X):\n",
    "        attr = self.rule_edges[0].get_feature()\n",
    "        if attr not in X.columns:\n",
    "            X.loc[:, attr] = np.nan\n",
    "        return X[attr].to_numpy()\n",
    "        \n",
    "    def get_edges(self, X):\n",
    "        X_np = self.prepare_df_for_attr(X)\n",
    "        rule_id = 1 if self.rule_edges[0].has_nan() else 0\n",
    "        query = self.rule_edges[rule_id].get_condition()\n",
    "        if self.rule_edges[0].get_feature() in self.categ:\n",
    "            values = np.isin(X_np, eval(query[query.find(\"[\"):]))\n",
    "        else:\n",
    "            values = eval(\"X_np\" + query)\n",
    "        return np.where(values, self.edges[rule_id], self.edges[1-rule_id])\n",
    "        \n",
    "    def predict(self, X, target, bins=None):\n",
    "        if target == \"surv\" or target == \"hazard\":\n",
    "            if target == \"surv\":\n",
    "                func_at_times = self.leaf_model.predict_survival_at_times(X, bins)  # target(X_node=dataset)\n",
    "            else:\n",
    "                func_at_times = self.leaf_model.predict_hazard_at_times(X, bins)\n",
    "            X[\"res\"] = X[\"res\"].apply(lambda x: func_at_times)\n",
    "        elif target == \"depth\":\n",
    "            X[\"res\"] = self.depth\n",
    "        elif target == \"num_node\":\n",
    "            X[\"res\"] = self.numb\n",
    "        else:\n",
    "            X[\"res\"] = self.leaf_model.predict_mean_feature(X, target)  # np.mean(dataset[target])\n",
    "        return X[\"res\"]\n",
    "    \n",
    "    \"\"\" GROUP FUNCTIONS: VISUALIZATION \"\"\"\n",
    "    \n",
    "    def get_figure(self, mode=\"hist\", bins=None, target=cnt.CENS_NAME, save_path=\"\"):\n",
    "        plt.ioff()\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        if mode == \"hist\":\n",
    "            lst = self.leaf_model.predict_list_feature(target)\n",
    "            plt.hist(lst, bins=25)\n",
    "            ax.set_xlim([0, np.max(lst)])\n",
    "            ax.set_xlabel(f'{target}', fontsize=25)\n",
    "        elif mode == \"surv\":\n",
    "            sf = self.leaf_model.predict_survival_at_times(X=None, bins=bins)\n",
    "            plt.step(bins, sf)\n",
    "            ax.set_xlabel('Time', fontsize=25)\n",
    "            ax.set_ylabel('Survival probability', fontsize=25)\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    def get_description(self):\n",
    "        m_cens = round(self.leaf_model.predict_mean_feature(X=None, feature_name=cnt.CENS_NAME), 2)\n",
    "        m_time = round(self.leaf_model.predict_mean_feature(X=None, feature_name=cnt.TIME_NAME), 2)\n",
    "        label = \"\\n\".join([f\"size = {self.leaf_model.get_shape()[0]}\",\n",
    "                           f\"cens/size = {m_cens}\",\n",
    "                           f\"depth = {self.depth}\",\n",
    "                           f\"death = {m_time}\"])\n",
    "        return label\n",
    "        \n",
    "    def set_dot_node(self, dot, path_dir=\"\", depth=None, **args):\n",
    "        if not(depth is None) and depth < self.depth :\n",
    "            return dot\n",
    "        img_path = path_dir + str(self.numb) + '.png'\n",
    "        self.get_figure(save_path=img_path, **args)\n",
    "        dot.node(str(self.numb), label=self.get_description(),\n",
    "                 image=img_path, fontsize='30')  # fontsize='16'\n",
    "        return dot\n",
    "    \n",
    "    def set_dot_edges(self, dot):\n",
    "        if not(self.is_leaf):\n",
    "            for e in range(len(self.rule_edges)):\n",
    "                s = self.rule_edges[e].to_str()\n",
    "                dot.edge(str(self.numb), str(self.edges[e]), label=s, fontsize='30')\n",
    "        return dot\n",
    "    \n",
    "    def translate(self, describe):\n",
    "        if self.is_leaf:\n",
    "            self.df = self.df.rename(describe, axis=1)\n",
    "        self.features = [describe.get(f, f) for f in self.features]\n",
    "        self.categ = [describe.get(c, c) for c in self.categ]\n",
    "        for e in range(len(self.rule_edges)):\n",
    "            self.rule_edges[e].translate(describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bef7d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "824adc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRAID1(object):\n",
    "    def __init__(self, depth = 0,\n",
    "                 random_state = 123,\n",
    "                 features = [],\n",
    "                 categ = [],\n",
    "                 cut = False,\n",
    "                 **info):\n",
    "        self.info = info\n",
    "        self.cut = cut\n",
    "        self.remove_files = []\n",
    "        self.nodes = dict()\n",
    "        self.depth = depth\n",
    "        self.features = features\n",
    "        self.categ = categ\n",
    "        self.random_state = random_state\n",
    "        self.name = \"CRAID_%s\" % (self.random_state)\n",
    "        self.coxph = None\n",
    "        self.ohenc = None\n",
    "        self.bins = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if len(self.features) == 0:\n",
    "            self.features = X.columns\n",
    "        self.bins = cnt.get_bins(time = y[cnt.TIME_NAME])#, cens = y[cnt.CENS_NAME])\n",
    "        X = X.reset_index(drop=True)\n",
    "        X_tr = X.copy()\n",
    "        X_tr[cnt.CENS_NAME] = y[cnt.CENS_NAME].astype(np.int32)\n",
    "        X_tr[cnt.TIME_NAME] = y[cnt.TIME_NAME].astype(np.int32)\n",
    "        \n",
    "        if not(\"min_samples_leaf\" in self.info):\n",
    "            self.info[\"min_samples_leaf\"] = 0.01*X_tr.shape[0]\n",
    "        cnt.set_seed(self.random_state)\n",
    "        \n",
    "        if self.cut:\n",
    "            X_val = X_tr.sample(n = int(0.2*X_tr.shape[0]), random_state=self.random_state)\n",
    "            X_tr = X_tr.loc[X_tr.index.difference(X_val.index),:]\n",
    "         \n",
    "        self.nodes[0] = Node(X_tr, features = self.features, categ = self.categ, **self.info)\n",
    "        stack_nodes = np.array([0], dtype = int)\n",
    "        while(stack_nodes.shape[0] > 0):\n",
    "            node = self.nodes[stack_nodes[0]]\n",
    "            stack_nodes = stack_nodes[1:]\n",
    "            if node.depth >= self.depth:\n",
    "                continue\n",
    "            sub_nodes = node.split()\n",
    "            if sub_nodes.shape[0] > 0:\n",
    "                sub_numbers = np.array([len(self.nodes) + i for i in range(sub_nodes.shape[0])])\n",
    "                for i in range(sub_nodes.shape[0]):\n",
    "                    sub_nodes[i].numb = sub_numbers[i]\n",
    "                self.nodes.update(dict(zip(sub_numbers, sub_nodes)))\n",
    "                node.set_edges(sub_numbers)\n",
    "                stack_nodes = np.append(stack_nodes, sub_numbers)\n",
    "                \n",
    "        if self.cut:\n",
    "            self.cut_tree(X_val, cnt.CENS_NAME, mode_f = roc_auc_score, choose_f = max)\n",
    "        \n",
    "        self.fit_cox_hazard(X, y)\n",
    "        self.count_list_rules()\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def fit_cox_hazard(self, X, y):\n",
    "        self.coxph = CoxPHSurvivalAnalysis(alpha = 0.1)\n",
    "        self.ohenc = OneHotEncoder(handle_unknown='ignore')\n",
    "        pred_node = self.predict(X, mode=\"target\", target = \"num_node\").to_numpy().reshape(-1,1)\n",
    "        ohenc_node = self.ohenc.fit_transform(pred_node).toarray()\n",
    "        self.coxph.fit(ohenc_node, y)\n",
    "        \n",
    "    def count_list_rules(self):\n",
    "        a = {0: []}\n",
    "        for k_node in sorted(self.nodes.keys()):\n",
    "            if not(self.nodes[k_node].is_leaf):\n",
    "                for edge, rule in zip(self.nodes[k_node].edges, self.nodes[k_node].rule_edges):\n",
    "                    a[edge] = a[k_node] + [rule]\n",
    "                del a[k_node]\n",
    "        self.list_rules = a\n",
    "        return self.list_rules\n",
    "        \n",
    "    \n",
    "    def predict_cox_hazard(self, X, bins):\n",
    "        bins = np.clip(bins, self.bins.min(), self.bins.max())\n",
    "        pred_node = self.predict(X, mode=\"target\", target=\"num_node\").to_numpy().reshape(-1,1)\n",
    "        ohenc_node = self.ohenc.transform(pred_node).toarray()\n",
    "        hazards = self.coxph.predict_cumulative_hazard_function(ohenc_node)\n",
    "        pred_haz = np.array(list(map(lambda x: x(bins), hazards)))\n",
    "        return pred_haz\n",
    "        \n",
    "    \n",
    "    def predict(self, X, mode=\"target\", target=cnt.TIME_NAME, end_list=[], bins=None):\n",
    "        X = format_to_pandas(X, self.features)\n",
    "        X.loc[:, \"number_node\"] = 0\n",
    "        X.loc[:, \"res\"] = np.nan\n",
    "        for i in sorted(self.nodes.keys()):\n",
    "            ind = X[X[\"number_node\"] == i].index\n",
    "            if ind.shape[0] > 0:\n",
    "                if self.nodes[i].is_leaf or (i in end_list):\n",
    "                    if target == \"surv\" or target == \"hazard\":\n",
    "                        X.loc[ind, \"res\"] = self.nodes[i].predict(X.loc[ind,:], target, bins)\n",
    "                    elif mode == \"target\":\n",
    "                        X.loc[ind, \"res\"] = self.nodes[i].predict(X.loc[ind,:], target)\n",
    "                    elif mode == \"scheme\":\n",
    "                        X.loc[ind, \"store_str\"] = \"\"\n",
    "                        X.loc[ind, \"res\"] = X[ind, \"res\"].apply(lambda x: dict())\n",
    "                        X.loc[ind, \"res\"] = self.tree.predict_scheme(X.loc[ind,:], target)\n",
    "                    elif mode == \"rules\":\n",
    "                        X.loc[ind, \"res\"] = \" & \".join([s.to_str() for s in self.list_rules[i]])\n",
    "                else:\n",
    "                    X.loc[ind, \"number_node\"] = self.nodes[i].get_edges(X.loc[ind,:])\n",
    "        return X[\"res\"]\n",
    "    \n",
    "    def predict_at_times(self, X, bins, mode=\"surv\"):\n",
    "        \"\"\"\n",
    "        Return survival or hazard function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Pandas dataframe\n",
    "            Contain input features of events.\n",
    "        bins : array-like\n",
    "            Points of timeline.\n",
    "        mode : str, optional\n",
    "            Type of function. The default is \"surv\".\n",
    "            \"surv\" : send building function in nodes\n",
    "            \"hazard\" : send building function in nodes\n",
    "            \"cox-hazard\" : fit CoxPH model on node numbers (input)\n",
    "                                          and time/cens (output)\n",
    "                       predict cumulative HF from model \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array-like\n",
    "            Vector of function values in times (bins).\n",
    "\n",
    "        \"\"\"\n",
    "        X = format_to_pandas(X, self.features)\n",
    "        if mode == \"cox-hazard\":\n",
    "            return self.predict_cox_hazard(X, bins)\n",
    "        return np.array(self.predict(X, target=mode, bins=bins).to_list())\n",
    "    \n",
    "    def predict_schemes(self, X, scheme_feats):\n",
    "        X = format_to_pandas(X, self.features)\n",
    "        num_node_to_key = dict(zip(sorted(self.nodes.keys()), range(len(self.nodes))))\n",
    "        node_bin = np.zeros((X.shape[0], len(self.nodes)), dtype=bool)\n",
    "        node_bin[:, 0] = 1\n",
    "        X[\"res\"] = np.nan\n",
    "        X[\"res\"] = X[\"res\"].apply(lambda x: list())\n",
    "        for i in sorted(self.nodes.keys()):\n",
    "            i_num = num_node_to_key[i]\n",
    "            ind = np.where(node_bin[:, i_num])[0]\n",
    "            ind_x = X.index[ind]\n",
    "            if ind.shape[0] > 0:\n",
    "                if self.nodes[i].is_leaf:\n",
    "                    X.loc[ind_x, \"res\"] = X.loc[ind_x, \"res\"].apply(lambda x: x + [i])\n",
    "                else:\n",
    "                    if self.nodes[i].rule_edges[0].get_feature() in scheme_feats:\n",
    "                        for e in self.nodes[i].edges:\n",
    "                            node_bin[ind, num_node_to_key[e]] = 1\n",
    "                    else:\n",
    "                        pred_edges = self.nodes[i].get_edges(X.iloc[ind,:])\n",
    "                        for e in set(pred_edges):\n",
    "                            node_bin[ind, num_node_to_key[e]] = pred_edges == e\n",
    "        return X[\"res\"]\n",
    "    \n",
    "    \n",
    "    def cut_tree(self, X, target, mode_f=roc_auc_score, choose_f=max):\n",
    "        \"\"\"\n",
    "        Method of prunning tree.\n",
    "        Find best subtree, which reaches best value of metric \"mode_f\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : Pandas dataframe\n",
    "            Contain input features of events.\n",
    "        target : str\n",
    "            Feature name for metric counting.\n",
    "        mode_f : function, optional\n",
    "            Metric for selecting. The default is roc_auc_score.\n",
    "        choose_f : function, optional\n",
    "            Type of best value (max or min). The default is max.\n",
    "\n",
    "        \"\"\"\n",
    "        self.nodes = cutted_tree(self, X, target, mode_f, choose_f).nodes\n",
    "        self.count_list_rules()\n",
    "    \n",
    "    def visualize(self, path_dir=None, **kwargs):\n",
    "        if path_dir is None:\n",
    "            path_dir = os.getcwd()\n",
    "        kwargs[\"bins\"] = self.bins\n",
    "        \n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "            dot = Digraph(node_attr={'shape': 'none'})\n",
    "            ordered_nodes = sorted(self.nodes.keys())\n",
    "            for i in ordered_nodes:\n",
    "                dot = self.nodes[i].set_dot_node(dot, path_dir=tmp_dir, **kwargs)\n",
    "            for i in ordered_nodes:\n",
    "                dot = self.nodes[i].set_dot_edges(dot)\n",
    "            dot.render(path_dir + self.name + \"_\", view=False, format=\"png\")\n",
    "    \n",
    "    def translate(self, describe):\n",
    "        self.features = [describe.get(f,f) for f in self.features]\n",
    "        self.categ = [describe.get(c,c) for c in self.categ]\n",
    "        for i in self.nodes.keys():\n",
    "            self.nodes[i].translate(describe)\n",
    "    \n",
    "    def get_leaf_numbers(self):\n",
    "        return np.array([i for i in self.nodes.keys() if self.nodes[i].is_leaf])\n",
    "    \n",
    "    def get_spanning_leaf_numbers(self):\n",
    "        leafs = self.get_leaf_numbers()\n",
    "        return np.array([i for i in self.nodes.keys()\n",
    "                         if np.intersect1d(self.nodes[i].edges, leafs).shape[0] == 2])\n",
    "    \n",
    "    def delete_leafs_by_span(self, list_span_leaf):\n",
    "        deleted_leafs = np.array([], dtype = int)\n",
    "        for i in list_span_leaf:\n",
    "            for e in self.nodes[i].edges:\n",
    "                del self.nodes[e]\n",
    "            self.nodes[i].set_leaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "56c1b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from survivors.datasets import load_pbc_dataset\n",
    "from survivors.experiments.grid import generate_sample\n",
    "\n",
    "X, y, features, categ, sch_nan = load_pbc_dataset()\n",
    "a = generate_sample(X, y, 5)\n",
    "X_train, y_train, X_test, y_test, bins = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a6f830de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL_TIME CRAID: 2.831928449915722 seconds\n",
      "FULL_TIME CRAID1: 1.637558045098558 seconds\n"
     ]
    }
   ],
   "source": [
    "params = {\"criterion\": \"peto\", \"depth\": 5, \"min_samples_leaf\": 3, \"signif\": 0.05, \"cut\": True}\n",
    "\n",
    "t_start = time.perf_counter()\n",
    "craid_tree = CRAID(**params)\n",
    "craid_tree.fit(X_train, y_train)\n",
    "print(f\"FULL_TIME CRAID: {time.perf_counter() - t_start} seconds\")\n",
    "\n",
    "t_start = time.perf_counter()\n",
    "craid_tree1 = CRAID1(**params)\n",
    "craid_tree1.fit(X_train, y_train)\n",
    "print(f\"FULL_TIME CRAID1: {time.perf_counter() - t_start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "dbcbada8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 11, 8: 12}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(range(len(craid_tree1.nodes)), sorted(craid_tree1.nodes.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0ffa1a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ = X_test.copy()\n",
    "X_[\"res\"] = 0\n",
    "X_.columns.get_loc(\"res\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9d61c923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trt</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>ascites</th>\n",
       "      <th>hepato</th>\n",
       "      <th>spiders</th>\n",
       "      <th>edema</th>\n",
       "      <th>bili</th>\n",
       "      <th>chol</th>\n",
       "      <th>albumin</th>\n",
       "      <th>copper</th>\n",
       "      <th>alk</th>\n",
       "      <th>ast</th>\n",
       "      <th>trig</th>\n",
       "      <th>platelet</th>\n",
       "      <th>protime</th>\n",
       "      <th>stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>58.765229</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>261.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1718.0</td>\n",
       "      <td>137.95</td>\n",
       "      <td>172.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56.446270</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>302.0</td>\n",
       "      <td>4.14</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7394.8</td>\n",
       "      <td>113.52</td>\n",
       "      <td>88.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>70.072553</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>176.0</td>\n",
       "      <td>3.48</td>\n",
       "      <td>210.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>96.10</td>\n",
       "      <td>55.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>54.740589</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>244.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6121.8</td>\n",
       "      <td>60.63</td>\n",
       "      <td>92.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>38.105407</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>279.0</td>\n",
       "      <td>3.53</td>\n",
       "      <td>143.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>113.15</td>\n",
       "      <td>72.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2.0</td>\n",
       "      <td>47.181383</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>316.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>147.25</td>\n",
       "      <td>137.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2.0</td>\n",
       "      <td>44.104038</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>268.0</td>\n",
       "      <td>4.08</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>86.80</td>\n",
       "      <td>95.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.0</td>\n",
       "      <td>63.613963</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>57.35</td>\n",
       "      <td>232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40.553046</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>448.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>127.10</td>\n",
       "      <td>175.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2.0</td>\n",
       "      <td>42.335387</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>578.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1353.0</td>\n",
       "      <td>127.10</td>\n",
       "      <td>105.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trt        age  sex  ascites  hepato  spiders  edema  bili   chol  \\\n",
       "0    1.0  58.765229    1      1.0     1.0      1.0    1.0  14.5  261.0   \n",
       "1    1.0  56.446270    1      0.0     1.0      1.0    0.0   1.1  302.0   \n",
       "2    1.0  70.072553    0      0.0     0.0      0.0    0.5   1.4  176.0   \n",
       "3    1.0  54.740589    1      0.0     1.0      1.0    0.5   1.8  244.0   \n",
       "4    2.0  38.105407    1      0.0     1.0      1.0    0.0   3.4  279.0   \n",
       "..   ...        ...  ...      ...     ...      ...    ...   ...    ...   \n",
       "124  2.0  47.181383    1      0.0     1.0      0.0    0.0   1.3  316.0   \n",
       "126  2.0  44.104038    1      0.0     0.0      0.0    0.0   0.5  268.0   \n",
       "128  1.0  63.613963    1      0.0     1.0      0.0    0.0   0.9  420.0   \n",
       "131  1.0  40.553046    1      0.0     0.0      0.0    0.0   1.9  448.0   \n",
       "133  2.0  42.335387    1      0.0     0.0      0.0    0.0   0.7  578.0   \n",
       "\n",
       "     albumin  copper     alk     ast   trig  platelet  protime  stage  \n",
       "0       2.60   156.0  1718.0  137.95  172.0     190.0     12.2    4.0  \n",
       "1       4.14    54.0  7394.8  113.52   88.0     221.0     10.6    3.0  \n",
       "2       3.48   210.0   516.0   96.10   55.0     151.0     12.0    4.0  \n",
       "3       2.54    64.0  6121.8   60.63   92.0     183.0     10.3    4.0  \n",
       "4       3.53   143.0   671.0  113.15   72.0     136.0     10.9    3.0  \n",
       "..       ...     ...     ...     ...    ...       ...      ...    ...  \n",
       "124     3.51    75.0  1162.0  147.25  137.0     238.0     10.0    4.0  \n",
       "126     4.08     9.0  1174.0   86.80   95.0     453.0     10.0    2.0  \n",
       "128     3.87    30.0  1009.0   57.35  232.0       NaN      9.7    3.0  \n",
       "131     3.83    60.0  1052.0  127.10  175.0     181.0      9.8    3.0  \n",
       "133     3.67    35.0  1353.0  127.10  105.0     427.0     10.7    2.0  \n",
       "\n",
       "[84 rows x 17 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3e868349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [3, 4, 5]\n",
       "1      [3, 4, 11, 12]\n",
       "2      [3, 4, 11, 12]\n",
       "3      [3, 4, 11, 12]\n",
       "4      [3, 4, 11, 12]\n",
       "            ...      \n",
       "124    [3, 4, 11, 12]\n",
       "126    [3, 4, 11, 12]\n",
       "128    [3, 4, 11, 12]\n",
       "131    [3, 4, 11, 12]\n",
       "133    [3, 4, 11, 12]\n",
       "Name: res, Length: 84, dtype: object"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craid_tree1.predict_schemes(X_test, [\"bili\", \"protime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "085bdd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ((bili >= 2.35)| nan) & ((protime >= 11.75)| nan)\n",
       "1      (bili < 2.35) & ((ascites < 0.5)| nan) & (bili...\n",
       "2      (bili < 2.35) & ((ascites < 0.5)| nan) & (bili...\n",
       "3      (bili < 2.35) & ((ascites < 0.5)| nan) & ((bil...\n",
       "4              ((bili >= 2.35)| nan) & (protime < 11.75)\n",
       "                             ...                        \n",
       "124    (bili < 2.35) & ((ascites < 0.5)| nan) & (bili...\n",
       "126    (bili < 2.35) & ((ascites < 0.5)| nan) & (bili...\n",
       "128    (bili < 2.35) & ((ascites < 0.5)| nan) & (bili...\n",
       "131    (bili < 2.35) & ((ascites < 0.5)| nan) & ((bil...\n",
       "133    (bili < 2.35) & ((ascites < 0.5)| nan) & (bili...\n",
       "Name: res, Length: 84, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craid_tree1.predict(X_test, mode=\"rules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61729ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ((bili >= 2.35)| не указано)&((protime >= 11.7...\n",
       "1      (bili < 2.35)&((ascites < 0.5)| не указано)&(b...\n",
       "2      (bili < 2.35)&((ascites < 0.5)| не указано)&(b...\n",
       "3      (bili < 2.35)&((ascites < 0.5)| не указано)&((...\n",
       "4         ((bili >= 2.35)| не указано)&(protime < 11.75)\n",
       "                             ...                        \n",
       "124    (bili < 2.35)&((ascites < 0.5)| не указано)&(b...\n",
       "126    (bili < 2.35)&((ascites < 0.5)| не указано)&(b...\n",
       "128    (bili < 2.35)&((ascites < 0.5)| не указано)&(b...\n",
       "131    (bili < 2.35)&((ascites < 0.5)| не указано)&((...\n",
       "133    (bili < 2.35)&((ascites < 0.5)| не указано)&(b...\n",
       "Name: res, Length: 84, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craid_tree.predict(X_test, mode=\"rules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6821d2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.2 ms ± 174 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "7.46 ms ± 5.72 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit craid_tree.predict(X_test, target=\"time\")\n",
    "%timeit craid_tree1.predict(X_test, target=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cd7be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (craid_tree.predict(X_test, target=\"time\") == craid_tree1.predict(X_test, target=\"time\")).all()\n",
    "assert (craid_tree.predict(X_test, target=\"cens\") == craid_tree1.predict(X_test, target=\"cens\")).all()\n",
    "assert (craid_tree.predict_at_times(X_test, bins=bins, mode=\"surv\") == craid_tree1.predict_at_times(X_test, bins=bins, mode=\"surv\")).all()\n",
    "assert (craid_tree.predict_at_times(X_test, bins=bins, mode=\"cox-hazard\") == craid_tree1.predict_at_times(X_test, bins=bins, mode=\"cox-hazard\")).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68dd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz  # doctest: +NO_EXE\n",
    "# doctest_mark_exe()\n",
    "\n",
    "# os.environ['PATH'] = os.environ['PATH'] + ';' + r\"C:\\ProgramData\\Anaconda3\\envs\\survive\\Library\\bin\"\n",
    "# # craid_tree.visualize(path_dir = \"./\", mode = \"surv\", target = \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ace04d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "craid_tree1.visualize(mode=\"surv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e99a4d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\vasiliev\\\\Desktop\\\\PycharmProjects\\\\dev-survivors\\\\demonstration'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912debf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
